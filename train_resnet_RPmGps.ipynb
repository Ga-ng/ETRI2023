{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa75dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import splitfolders\n",
    "import torchsummary\n",
    "from tqdm import tqdm\n",
    "from ResNet_18 import resnet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990b3869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789a6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':50,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc11a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f5b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_data.csv', index_col = 0)\n",
    "test_df = pd.read_csv('./test_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a8786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le = le.fit(train_df['action'])\n",
    "train_df['action'] = le.transform(train_df['action'])\n",
    "test_df['action'] = le.transform(test_df['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9b1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = []\n",
    "for i in range(15):\n",
    "    path_list = list(train_df[train_df['action']==i]['img_path'])\n",
    "    if len(path_list) >= 5000:\n",
    "        tmp = random.sample(path_list, 5000)\n",
    "        for i in tmp:\n",
    "            img_path_list.append(i)\n",
    "    else:\n",
    "        for i in path_list:\n",
    "            img_path_list.append(i)\n",
    "df = pd.DataFrame(img_path_list)\n",
    "df.columns = ['img_path']\n",
    "df\n",
    "\n",
    "path_label_df = pd.merge(train_df, df, on='img_path', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14395dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "14    5000\n13    5000\n8     5000\n4     4381\n6     3968\n12    2534\n3     2481\n10    2406\n7     2291\n1     2187\n11    2144\n9     1995\n5     1927\n2     1580\n0      619\nName: action, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_label_df['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c8ed8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      action                                           img_path  user_x  \\\n0         13  ./ETRI_data_RP_png/user03/1600876800/RP/160090...  user03   \n1         10  ./ETRI_data_RP_png/user26/1599836400/RP/159985...  user26   \n2          6  ./ETRI_data_RP_png/user27/1600309320/RP/160031...  user27   \n3          5  ./ETRI_data_RP_png/user04/1599957060/RP/159997...  user04   \n4         11  ./ETRI_data_RP_png/user02/1598972400/RP/159903...  user02   \n...      ...                                                ...     ...   \n3724      13  ./ETRI_data_RP_png/user03/1599928800/RP/159999...  user03   \n3725       8  ./ETRI_data_RP_png/user03/1601141400/RP/160121...  user03   \n3726      13  ./ETRI_data_RP_png/user03/1600448400/RP/160048...  user03   \n3727       4  ./ETRI_data_RP_png/user04/1599690000/RP/159970...  user04   \n3728      12  ./ETRI_data_RP_png/user01/1600831800/RP/160086...  user01   \n\n            lat         lon  \n0     37.488120  126.982263  \n1     37.554346  126.922069  \n2     37.529723  127.008367  \n3     37.434939  127.138877  \n4     37.521560  127.032720  \n...         ...         ...  \n3724  37.283530  126.980865  \n3725  37.485415  126.977617  \n3726  37.517630  127.089633  \n3727  37.464091  127.127168  \n3728  37.482461  126.956358  \n\n[3729 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action</th>\n      <th>img_path</th>\n      <th>user_x</th>\n      <th>lat</th>\n      <th>lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>./ETRI_data_RP_png/user03/1600876800/RP/160090...</td>\n      <td>user03</td>\n      <td>37.488120</td>\n      <td>126.982263</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>./ETRI_data_RP_png/user26/1599836400/RP/159985...</td>\n      <td>user26</td>\n      <td>37.554346</td>\n      <td>126.922069</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>./ETRI_data_RP_png/user27/1600309320/RP/160031...</td>\n      <td>user27</td>\n      <td>37.529723</td>\n      <td>127.008367</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>./ETRI_data_RP_png/user04/1599957060/RP/159997...</td>\n      <td>user04</td>\n      <td>37.434939</td>\n      <td>127.138877</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>./ETRI_data_RP_png/user02/1598972400/RP/159903...</td>\n      <td>user02</td>\n      <td>37.521560</td>\n      <td>127.032720</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3724</th>\n      <td>13</td>\n      <td>./ETRI_data_RP_png/user03/1599928800/RP/159999...</td>\n      <td>user03</td>\n      <td>37.283530</td>\n      <td>126.980865</td>\n    </tr>\n    <tr>\n      <th>3725</th>\n      <td>8</td>\n      <td>./ETRI_data_RP_png/user03/1601141400/RP/160121...</td>\n      <td>user03</td>\n      <td>37.485415</td>\n      <td>126.977617</td>\n    </tr>\n    <tr>\n      <th>3726</th>\n      <td>13</td>\n      <td>./ETRI_data_RP_png/user03/1600448400/RP/160048...</td>\n      <td>user03</td>\n      <td>37.517630</td>\n      <td>127.089633</td>\n    </tr>\n    <tr>\n      <th>3727</th>\n      <td>4</td>\n      <td>./ETRI_data_RP_png/user04/1599690000/RP/159970...</td>\n      <td>user04</td>\n      <td>37.464091</td>\n      <td>127.127168</td>\n    </tr>\n    <tr>\n      <th>3728</th>\n      <td>12</td>\n      <td>./ETRI_data_RP_png/user01/1600831800/RP/160086...</td>\n      <td>user01</td>\n      <td>37.482461</td>\n      <td>126.956358</td>\n    </tr>\n  </tbody>\n</table>\n<p>3729 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list = []\n",
    "for i in range(15):\n",
    "    path_list = list(test_df[test_df['action']==i]['img_path'])\n",
    "    if len(path_list) >= 300:\n",
    "        tmp = random.sample(path_list, 300)\n",
    "        for i in tmp:\n",
    "            img_path_list.append(i)\n",
    "    else:\n",
    "        for i in path_list:\n",
    "            img_path_list.append(i)\n",
    "df2 = pd.DataFrame(img_path_list)\n",
    "df2.columns = ['img_path']\n",
    "df2\n",
    "\n",
    "path_label_df2 = pd.merge(test_df, df2, on='img_path', how='inner')\n",
    "path_label_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2120d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "13    300\n6     300\n8     300\n14    300\n4     300\n12    273\n10    271\n3     271\n11    250\n7     248\n1     247\n9     220\n5     208\n2     158\n0      83\nName: action, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_label_df2['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903289c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = path_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2392af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = path_label_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392e1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(train_df, train_df['action'], test_size=0.1, random_state=CFG['SEED'], stratify=train_df['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d01d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['img_path'] = train['img_path'].apply(lambda x : x.replace('./ETRI_data_RP_png', '../ETRIdata'))\n",
    "val['img_path'] = val['img_path'].apply(lambda x : x.replace('./ETRI_data_RP_png', '../ETRIdata'))\n",
    "test_df['img_path'] = train_df['img_path'].apply(lambda x : x.replace('./ETRI_data_RP_png', '../ETRIdata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5976ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       action                                         img_path  user_x  \\\n41386       3  ../ETRIdata/user03/1600876800/RP/1600952820.png  user03   \n36791      10  ../ETRIdata/user01/1601166300/RP/1601193840.png  user01   \n18443       6  ../ETRIdata/user26/1600095600/RP/1600155180.png  user26   \n27588      12  ../ETRIdata/user09/1600403400/RP/1600414800.png  user09   \n7780       14  ../ETRIdata/user04/1600207800/RP/1600247820.png  user04   \n...       ...                                              ...     ...   \n10322       6  ../ETRIdata/user06/1601912160/RP/1601986620.png  user06   \n10575       1  ../ETRIdata/user26/1600441200/RP/1600497840.png  user26   \n21870       7  ../ETRIdata/user04/1600558200/RP/1600583160.png  user04   \n23790       8  ../ETRIdata/user03/1599928800/RP/1600005840.png  user03   \n14813      13  ../ETRIdata/user01/1601085900/RP/1601124600.png  user01   \n\n             lat         lon  \n41386  37.485394  126.977561  \n36791  37.482449  126.956348  \n18443  37.278514  127.163543  \n27588  37.381507  127.230470  \n7780   37.477683  127.122614  \n...          ...         ...  \n10322  37.513558  127.045732  \n10575  37.242523  127.390785  \n21870  37.434926  127.138867  \n23790  37.485407  126.977599  \n14813  37.497442  127.033842  \n\n[39161 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action</th>\n      <th>img_path</th>\n      <th>user_x</th>\n      <th>lat</th>\n      <th>lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41386</th>\n      <td>3</td>\n      <td>../ETRIdata/user03/1600876800/RP/1600952820.png</td>\n      <td>user03</td>\n      <td>37.485394</td>\n      <td>126.977561</td>\n    </tr>\n    <tr>\n      <th>36791</th>\n      <td>10</td>\n      <td>../ETRIdata/user01/1601166300/RP/1601193840.png</td>\n      <td>user01</td>\n      <td>37.482449</td>\n      <td>126.956348</td>\n    </tr>\n    <tr>\n      <th>18443</th>\n      <td>6</td>\n      <td>../ETRIdata/user26/1600095600/RP/1600155180.png</td>\n      <td>user26</td>\n      <td>37.278514</td>\n      <td>127.163543</td>\n    </tr>\n    <tr>\n      <th>27588</th>\n      <td>12</td>\n      <td>../ETRIdata/user09/1600403400/RP/1600414800.png</td>\n      <td>user09</td>\n      <td>37.381507</td>\n      <td>127.230470</td>\n    </tr>\n    <tr>\n      <th>7780</th>\n      <td>14</td>\n      <td>../ETRIdata/user04/1600207800/RP/1600247820.png</td>\n      <td>user04</td>\n      <td>37.477683</td>\n      <td>127.122614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10322</th>\n      <td>6</td>\n      <td>../ETRIdata/user06/1601912160/RP/1601986620.png</td>\n      <td>user06</td>\n      <td>37.513558</td>\n      <td>127.045732</td>\n    </tr>\n    <tr>\n      <th>10575</th>\n      <td>1</td>\n      <td>../ETRIdata/user26/1600441200/RP/1600497840.png</td>\n      <td>user26</td>\n      <td>37.242523</td>\n      <td>127.390785</td>\n    </tr>\n    <tr>\n      <th>21870</th>\n      <td>7</td>\n      <td>../ETRIdata/user04/1600558200/RP/1600583160.png</td>\n      <td>user04</td>\n      <td>37.434926</td>\n      <td>127.138867</td>\n    </tr>\n    <tr>\n      <th>23790</th>\n      <td>8</td>\n      <td>../ETRIdata/user03/1599928800/RP/1600005840.png</td>\n      <td>user03</td>\n      <td>37.485407</td>\n      <td>126.977599</td>\n    </tr>\n    <tr>\n      <th>14813</th>\n      <td>13</td>\n      <td>../ETRIdata/user01/1601085900/RP/1601124600.png</td>\n      <td>user01</td>\n      <td>37.497442</td>\n      <td>127.033842</td>\n    </tr>\n  </tbody>\n</table>\n<p>39161 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c86927",
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_tfms = A.Compose([\n",
    "    A.Resize(width=CFG['IMG_SIZE'], height=CFG['IMG_SIZE']),\n",
    "    A.Normalize()\n",
    "], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f567a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gps_tfms = A.Compose([\n",
    "    A.Resize(width=112, height=112),\n",
    "    A.Normalize()\n",
    "], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86628c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPDataset(Dataset):\n",
    "    def __init__(self, df, rp_path_list, label_list, tfms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.rp_path_list = rp_path_list\n",
    "        self.label_list = label_list\n",
    "        self.tfms = tfms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.rp_path_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = self.tfms(image=img)['image']\n",
    "        image = torch.tensor(np.array(image)).permute(2, 0, 1)\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d28b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GpsDataset(Dataset):\n",
    "    def __init__(self, df, lat_path_list, lon_path_list, label_list, tfms=None):\n",
    "        super(GpsDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.lat_path_list = lat_path_list\n",
    "        self.lon_path_list = lon_path_list\n",
    "        self.label_list = label_list\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lat = self.lat_path_list[idx]\n",
    "        lon = self.lon_path_list[idx]\n",
    "        feature_map = torch.tensor(np.array([lat, lon]))\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[idx]\n",
    "            return feature_map, label\n",
    "        else:\n",
    "            return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "       action                                         img_path  user_x  \\\n41386       3  ../ETRIdata/user03/1600876800/RP/1600952820.png  user03   \n36791      10  ../ETRIdata/user01/1601166300/RP/1601193840.png  user01   \n18443       6  ../ETRIdata/user26/1600095600/RP/1600155180.png  user26   \n27588      12  ../ETRIdata/user09/1600403400/RP/1600414800.png  user09   \n7780       14  ../ETRIdata/user04/1600207800/RP/1600247820.png  user04   \n...       ...                                              ...     ...   \n10322       6  ../ETRIdata/user06/1601912160/RP/1601986620.png  user06   \n10575       1  ../ETRIdata/user26/1600441200/RP/1600497840.png  user26   \n21870       7  ../ETRIdata/user04/1600558200/RP/1600583160.png  user04   \n23790       8  ../ETRIdata/user03/1599928800/RP/1600005840.png  user03   \n14813      13  ../ETRIdata/user01/1601085900/RP/1601124600.png  user01   \n\n             lat         lon  \n41386  37.485394  126.977561  \n36791  37.482449  126.956348  \n18443  37.278514  127.163543  \n27588  37.381507  127.230470  \n7780   37.477683  127.122614  \n...          ...         ...  \n10322  37.513558  127.045732  \n10575  37.242523  127.390785  \n21870  37.434926  127.138867  \n23790  37.485407  126.977599  \n14813  37.497442  127.033842  \n\n[39161 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action</th>\n      <th>img_path</th>\n      <th>user_x</th>\n      <th>lat</th>\n      <th>lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41386</th>\n      <td>3</td>\n      <td>../ETRIdata/user03/1600876800/RP/1600952820.png</td>\n      <td>user03</td>\n      <td>37.485394</td>\n      <td>126.977561</td>\n    </tr>\n    <tr>\n      <th>36791</th>\n      <td>10</td>\n      <td>../ETRIdata/user01/1601166300/RP/1601193840.png</td>\n      <td>user01</td>\n      <td>37.482449</td>\n      <td>126.956348</td>\n    </tr>\n    <tr>\n      <th>18443</th>\n      <td>6</td>\n      <td>../ETRIdata/user26/1600095600/RP/1600155180.png</td>\n      <td>user26</td>\n      <td>37.278514</td>\n      <td>127.163543</td>\n    </tr>\n    <tr>\n      <th>27588</th>\n      <td>12</td>\n      <td>../ETRIdata/user09/1600403400/RP/1600414800.png</td>\n      <td>user09</td>\n      <td>37.381507</td>\n      <td>127.230470</td>\n    </tr>\n    <tr>\n      <th>7780</th>\n      <td>14</td>\n      <td>../ETRIdata/user04/1600207800/RP/1600247820.png</td>\n      <td>user04</td>\n      <td>37.477683</td>\n      <td>127.122614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10322</th>\n      <td>6</td>\n      <td>../ETRIdata/user06/1601912160/RP/1601986620.png</td>\n      <td>user06</td>\n      <td>37.513558</td>\n      <td>127.045732</td>\n    </tr>\n    <tr>\n      <th>10575</th>\n      <td>1</td>\n      <td>../ETRIdata/user26/1600441200/RP/1600497840.png</td>\n      <td>user26</td>\n      <td>37.242523</td>\n      <td>127.390785</td>\n    </tr>\n    <tr>\n      <th>21870</th>\n      <td>7</td>\n      <td>../ETRIdata/user04/1600558200/RP/1600583160.png</td>\n      <td>user04</td>\n      <td>37.434926</td>\n      <td>127.138867</td>\n    </tr>\n    <tr>\n      <th>23790</th>\n      <td>8</td>\n      <td>../ETRIdata/user03/1599928800/RP/1600005840.png</td>\n      <td>user03</td>\n      <td>37.485407</td>\n      <td>126.977599</td>\n    </tr>\n    <tr>\n      <th>14813</th>\n      <td>13</td>\n      <td>../ETRIdata/user01/1601085900/RP/1601124600.png</td>\n      <td>user01</td>\n      <td>37.497442</td>\n      <td>127.033842</td>\n    </tr>\n  </tbody>\n</table>\n<p>39161 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0adae7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_train_dataset = RPDataset(df=train, rp_path_list=train['img_path'].values, label_list=train['action'].values, tfms=RP_tfms)\n",
    "RP_train_loader = DataLoader(RP_train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "RP_val_dataset = RPDataset(df=val,rp_path_list=val['img_path'].values, label_list=val['action'].values, tfms=RP_tfms)\n",
    "RP_val_loader = DataLoader(RP_val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1801d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gps_train_dataset = GpsDataset(df=train, lat_path_list=train['lat'].values, lon_path_list=train['lon'].values, label_list=train['action'].values, tfms=Gps_tfms)\n",
    "Gps_train_loader = DataLoader(Gps_train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "Gps_val_dataset = GpsDataset(df=val, lat_path_list=train['lat'].values, lon_path_list=train['lon'].values, label_list=val['action'].values, tfms=Gps_tfms)\n",
    "Gps_val_loader = DataLoader(Gps_val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94f86f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction=self.reduction)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1-pt)**self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f5ae148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        bias=False,\n",
    "        padding = 1,\n",
    "        padding_mode='zeros'\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        bias=False,\n",
    "        padding = 1,\n",
    "        padding_mode='zeros'\n",
    "    )\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channel, channel, 1, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel, channel, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        y = self.attention(x)\n",
    "        return x * y\n",
    "    \n",
    "class CAB(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(CAB, self).__init__()\n",
    "        self.cab = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel, kernel_size=3, padding=1, stride=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel, channel, kernel_size=3, padding=1, stride=1),\n",
    "            ChannelAttention(channel)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.cab(x)\n",
    "\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride = 1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(in_planes, out_planes, stride)\n",
    "#         self.cab = CAB(out_planes)\n",
    "        self.conv2 = conv3x3(out_planes, out_planes, 1)\n",
    "\n",
    "        self.bn1   = nn.BatchNorm2d(out_planes)\n",
    "        self.bn2   = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                conv1x1(in_planes, out_planes, stride),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out  = self.conv2(out)\n",
    "#         out = self.cab(out)\n",
    "        out  = self.bn2(out)\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, in_planes, num_blocks, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "#         self.conv = nn.Conv2d(3, in_planes, kernel_size = 3, stride = 1, padding = 1, padding_mode='zeros', bias=False)\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 3, padding_mode='zeros', bias=False)\n",
    "        self.cab = CAB(in_planes)\n",
    "#         self.bn = nn.BatchNorm2d(self.in_planes)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.layer1 = self.make_layer(block, in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(block, in_planes, num_blocks[1], stride=1)\n",
    "        self.layer3 = self.make_layer(block, in_planes, num_blocks[2], stride=1)\n",
    "        self.layer4 = self.make_layer(block, in_planes, num_blocks[3], stride=1)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear  = nn.Linear(in_planes + 2, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_planes, num_blocks, stride):\n",
    "            strides = [stride] + [1] * (num_blocks -1)\n",
    "            layers = []\n",
    "            for stride in strides:\n",
    "                layers.append(block(self.in_planes, out_planes))\n",
    "                self.in_planes = out_planes\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, g):\n",
    "        out = self.conv(x)\n",
    "        out = self.cab(out)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "#         print(out.shape)\n",
    "        g = g.unsqueeze(-1).unsqueeze(-1)\n",
    "        g = g.expand(-1, -1, 1, 1).float()\n",
    "#         g = self.avgpool(g)\n",
    "#         print(g.shape)\n",
    "        out = torch.cat((out, g), dim=1)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(in_planes, num_classes):\n",
    "    return ResNet(block = IdentityBlock, in_planes = in_planes, num_blocks = [2, 2, 2, 2], num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a20fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "in_planes = 64\n",
    "num_classes = 15\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        bias=False,\n",
    "        padding = 1,\n",
    "        padding_mode='zeros'\n",
    "    )\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, numIn, numOut, stride = 1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.numIn = numIn\n",
    "        self.numOut = numOut\n",
    "        self.stride = stride\n",
    "        self.conv1 = nn.Conv2d(self.numIn, self.numOut, bias = False, kernel_size = 3,stride = self.stride,padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.numOut)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.conv2 = nn.Conv2d(self.numOut, self.numOut, bias = False, kernel_size = 3, stride = self.stride, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.numOut)\n",
    "        \n",
    "        if self.numIn != self.numOut:\n",
    "            self.conv4 = nn.Conv2d(self.numIn, self.numOut, bias = True, kernel_size = 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        if self.numIn != self.numOut:\n",
    "            residual = self.conv4(x)\n",
    "        \n",
    "        return out + residual\n",
    "    \n",
    "class CAB(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(CAB, self).__init__()\n",
    "        self.cab = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel, kernel_size=3, padding=1, stride=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channel, channel, kernel_size=3, padding=1, stride=1),\n",
    "            ChannelAttention(channel)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.cab(x)\n",
    "    \n",
    "\n",
    "class  ResNet_CAM(nn.Module):\n",
    "    def __init__(self,nOut):\n",
    "        super(ResNet_CAM, self).__init__()\n",
    "        self.cab1 = CAB(32)\n",
    "        self.cab2 = CAB(34)\n",
    "        self.nOut = nOut\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 3,bias = False)#320\n",
    "        self.conv2 = conv3x3(34, 34, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.res1 = Residual(32,32)\n",
    "        self.res2 = Residual(32,32)\n",
    "        \n",
    "        self.res3 = Residual(32,32)\n",
    "        self.res4 = Residual(32,32)\n",
    "        \n",
    "        self.res5 = Residual(32,32)\n",
    "        self.res6 = Residual(32,32)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear  = nn.Linear(in_planes//2 + 2, num_classes)\n",
    "        \n",
    "        self.lr1 = nn.Linear(64*16*16,256)\n",
    "        self.gap = nn.AvgPool2d(kernel_size = 14, stride = 1)\n",
    "        self.lr1 = nn.Linear(32,nOut)\n",
    "        self.lr2 = nn.Linear(256,nOut)\n",
    "\n",
    "    def forward(self, out, g):#Bx3X224x224\n",
    "        out = self.conv1(out)#Bx64x224x224\n",
    "        out = self.cab1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)#Bx64x112x112\n",
    "        out = self.res1(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.maxpool(out)#Bx64x56x56\n",
    "        out = self.res3(out)\n",
    "        out = self.res4(out)\n",
    "        out = self.maxpool(out)#Bx64x28x28\n",
    "        out = self.res5(out)\n",
    "        out = self.res6(out)\n",
    "        out = self.maxpool(out)#Bx64x14x14\n",
    "        out = self.avgpool(out)\n",
    "#         print(out.shape)\n",
    "        g = g.unsqueeze(-1).unsqueeze(-1)\n",
    "        g = g.expand(-1, -1, 1, 1).float()\n",
    "        out = torch.cat((out, g), dim=1)\n",
    "#         print(out.shape)\n",
    "        out = self.cab2(out)\n",
    "#         print(out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eb09fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(zip(tqdm(RP_val_loader), Gps_val_loader)):\n",
    "            data1, data2 = data\n",
    "            images, labels = data1\n",
    "            gps, _ = data2\n",
    "            \n",
    "            images = images.to(device)\n",
    "            gps = gps.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logit = model(images)\n",
    "            \n",
    "            loss = criterion(logit, labels)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            trues += labels.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "    \n",
    "    _val_score = f1_score(trues, preds, average='micro')\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3724661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, device):\n",
    "    model.to(device)\n",
    "#     criterion = FocalLoss().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        val_loss = []\n",
    "        preds, trues = [], []\n",
    "    \n",
    "        for i, data in enumerate(zip(tqdm(RP_train_loader), Gps_train_loader)):\n",
    "            data1, data2 = data\n",
    "            images, labels = data1\n",
    "            gps, _ = data2\n",
    "            \n",
    "            images = images.to(device)\n",
    "            gps = gps.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        model.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(zip(tqdm(RP_val_loader), Gps_val_loader)):\n",
    "                data1, data2 = data\n",
    "                images, labels = data1\n",
    "                gps, _ = data2\n",
    "\n",
    "                images = images.to(device)\n",
    "                gps = gps.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                logit = model(images)\n",
    "\n",
    "                loss = criterion(logit, labels)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "                trues += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            _val_loss = np.mean(val_loss)\n",
    "\n",
    "        _val_score = f1_score(trues, preds, average='micro')\n",
    "\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 : [{_val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1822c2eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jh/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = resnet.ResNet18(64, 15)\n",
    "# model = ResNet18(64, 15)\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:58<00:00,  2.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:32<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [2.55004] Val Loss : [2.49529] Val F1 : [0.17188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:51<00:00,  2.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [2.45308] Val Loss : [2.38576] Val F1 : [0.23415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:51<00:00,  2.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [2.39440] Val Loss : [2.36226] Val F1 : [0.24770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:50<00:00,  2.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [2.35308] Val Loss : [2.32530] Val F1 : [0.25574]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:52<00:00,  2.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [2.31848] Val Loss : [2.29389] Val F1 : [0.27275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:58<00:00,  2.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [2.28199] Val Loss : [2.30926] Val F1 : [0.26792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:55<00:00,  2.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [2.25384] Val Loss : [2.26352] Val F1 : [0.27872]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:52<00:00,  2.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [2.22272] Val Loss : [2.28078] Val F1 : [0.27734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:50<00:00,  2.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [2.19451] Val Loss : [2.25245] Val F1 : [0.28837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:30<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [2.16501] Val Loss : [2.24086] Val F1 : [0.29504]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [2.12285] Val Loss : [2.23766] Val F1 : [0.29848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [2.08299] Val Loss : [2.26546] Val F1 : [0.29619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [2.04179] Val Loss : [2.32883] Val F1 : [0.27987]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [1.98885] Val Loss : [2.35079] Val F1 : [0.29205]\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [1.78022] Val Loss : [2.38558] Val F1 : [0.28745]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [1.59726] Val Loss : [2.58589] Val F1 : [0.27091]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [1.40544] Val Loss : [2.81788] Val F1 : [0.27413]\n",
      "Epoch 00017: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [1.05212] Val Loss : [3.32388] Val F1 : [0.25919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.81885] Val Loss : [3.80912] Val F1 : [0.26585]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.62924] Val Loss : [4.47674] Val F1 : [0.25414]\n",
      "Epoch 00020: reducing learning rate of group 0 to 3.7500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.42528] Val Loss : [5.26667] Val F1 : [0.24954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.32982] Val Loss : [5.87306] Val F1 : [0.25391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.27550] Val Loss : [6.36595] Val F1 : [0.25299]\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.8750e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.21014] Val Loss : [6.81309] Val F1 : [0.25391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.18369] Val Loss : [7.20006] Val F1 : [0.25506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.16058] Val Loss : [7.62806] Val F1 : [0.25276]\n",
      "Epoch 00026: reducing learning rate of group 0 to 9.3750e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.14161] Val Loss : [7.93036] Val F1 : [0.25506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.13283] Val Loss : [8.10717] Val F1 : [0.25460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.12333] Val Loss : [8.33465] Val F1 : [0.25551]\n",
      "Epoch 00029: reducing learning rate of group 0 to 4.6875e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Train Loss : [0.11402] Val Loss : [8.50471] Val F1 : [0.25460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Train Loss : [0.11010] Val Loss : [8.54390] Val F1 : [0.25483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Train Loss : [0.10742] Val Loss : [8.69961] Val F1 : [0.25574]\n",
      "Epoch 00032: reducing learning rate of group 0 to 2.3437e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Train Loss : [0.09992] Val Loss : [8.78452] Val F1 : [0.25666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Train Loss : [0.10015] Val Loss : [8.85126] Val F1 : [0.25735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Train Loss : [0.09692] Val Loss : [8.90442] Val F1 : [0.25551]\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.1719e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Train Loss : [0.09733] Val Loss : [8.97364] Val F1 : [0.25574]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Train Loss : [0.09734] Val Loss : [9.02421] Val F1 : [0.25368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Train Loss : [0.09542] Val Loss : [9.02155] Val F1 : [0.25620]\n",
      "Epoch 00038: reducing learning rate of group 0 to 5.8594e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Train Loss : [0.09312] Val Loss : [9.02971] Val F1 : [0.25528]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Train Loss : [0.09401] Val Loss : [9.05835] Val F1 : [0.25551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Train Loss : [0.09369] Val Loss : [9.06950] Val F1 : [0.25620]\n",
      "Epoch 00041: reducing learning rate of group 0 to 2.9297e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Train Loss : [0.09335] Val Loss : [9.08128] Val F1 : [0.25551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Train Loss : [0.09271] Val Loss : [9.08607] Val F1 : [0.25666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Train Loss : [0.09153] Val Loss : [9.09728] Val F1 : [0.25597]\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.4648e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Train Loss : [0.09277] Val Loss : [9.09566] Val F1 : [0.25597]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Train Loss : [0.09150] Val Loss : [9.10112] Val F1 : [0.25597]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Train Loss : [0.09180] Val Loss : [9.10698] Val F1 : [0.25597]\n",
      "Epoch 00047: reducing learning rate of group 0 to 7.3242e-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:40<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Train Loss : [0.09250] Val Loss : [9.10872] Val F1 : [0.25666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Train Loss : [0.09031] Val Loss : [9.11026] Val F1 : [0.25643]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [08:39<00:00,  2.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136/136 [00:29<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50], Train Loss : [0.09102] Val Loss : [9.11502] Val F1 : [0.25597]\n",
      "Epoch 00050: reducing learning rate of group 0 to 3.6621e-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 15)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, scheduler, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_test_dataset = RPDataset(df=test_df, rp_path_list=test_df['img_path'].values, label_list=test_df['action'].values, tfms=RP_tfms)\n",
    "RP_test_loader = DataLoader(RP_test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "Gps_test_dataset = GpsDataset(df=test_df, lat_path_list=test_df['lat'].values, lon_path_list=test_df['lon'].values, label_list=test_df['action'].values, tfms=Gps_tfms)\n",
    "Gps_test_loader = DataLoader(Gps_test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4233fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(zip(tqdm(RP_test_loader), Gps_test_loader)):\n",
    "            data1, data2 = data\n",
    "            images, labels = data1\n",
    "            gps, _ = data2\n",
    "            \n",
    "            images = images.to(device)\n",
    "            gps = gps.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logit = model(images)\n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c708f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(test_df['action'], preds, labels=[x for x in range(0, 15)])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (25,25))\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb171de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(test_df['action'], preds, average='micro')\n",
    "print('F1-score: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf166d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'./save_model/0425_RPmGps_lr3e4_pre.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f32754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = test_df['action']\n",
    "y_pred = preds\n",
    "target_names = [str(x) for x in range(15)]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df['action']\n",
    "y_pred = preds\n",
    "target_names = [str(x) for x in range(15)]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcd945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
