{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e982fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from lstm import LSTM\n",
    "\n",
    "df = pd.read_csv('../../dataset_2020/user24/1599690600/eda_temp/1599696480.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "csv_file_train = pd.read_csv('/home/jh/ETRIdata/ETRItrain.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39060 entries, 0 to 39059\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  39060 non-null  int64  \n",
      " 1   ts          39060 non-null  float64\n",
      " 2   action      39060 non-null  object \n",
      " 3   img_path    39060 non-null  object \n",
      " 4   eda_temp    39060 non-null  object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "csv_file_train['']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2ac80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SEQ_LENGTH':240,\n",
    "    'INPUT_DIM':2,\n",
    "    'HIDDEN_DIM':10,\n",
    "    'OUTPUT_DIM':1,\n",
    "    'EPOCHS':100,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':100,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c5e3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b75b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, seq_len):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    for i in range(len(data)-CFG['SEQ_LENGTH']):\n",
    "        x = data[i:i+seq_len, :]\n",
    "        y = data[i+seq_len]\n",
    "        \n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "# df = df[['timestamp', 'eda', 'temp']]\n",
    "df = df[['eda', 'temp']]\n",
    "df = df.fillna(0)\n",
    "\n",
    "train_size = int(len(df)*0.8)\n",
    "train_set = df[0:train_size]\n",
    "val_set = df[train_size-CFG['SEQ_LENGTH']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f46b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          eda   temp\n0    0.285685  33.79\n1    0.286966  33.79\n2    0.284404  33.79\n3    0.284404  33.79\n4    0.285685  33.81\n..        ...    ...\n187  0.283123  34.07\n188  0.283123  34.05\n189  0.284404  34.05\n190  0.283123  34.05\n191  0.283123  34.05\n\n[192 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eda</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.285685</td>\n      <td>33.79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.286966</td>\n      <td>33.79</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.284404</td>\n      <td>33.79</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.284404</td>\n      <td>33.79</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.285685</td>\n      <td>33.81</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>0.283123</td>\n      <td>34.07</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>0.283123</td>\n      <td>34.05</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>0.284404</td>\n      <td>34.05</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>0.283123</td>\n      <td>34.05</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>0.283123</td>\n      <td>34.05</td>\n    </tr>\n  </tbody>\n</table>\n<p>192 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93d615dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          eda   temp\n172  0.293372  34.03\n173  0.295934  34.03\n174  0.293372  34.03\n175  0.293372  34.03\n176  0.294653  34.07\n..        ...    ...\n235  0.283123  34.09\n236  0.284404  34.09\n237  0.283123  34.09\n238  0.283123  34.09\n239  0.283123  34.09\n\n[68 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eda</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>172</th>\n      <td>0.293372</td>\n      <td>34.03</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>0.295934</td>\n      <td>34.03</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>0.293372</td>\n      <td>34.03</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>0.293372</td>\n      <td>34.03</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>0.294653</td>\n      <td>34.07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>0.283123</td>\n      <td>34.09</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>0.284404</td>\n      <td>34.09</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>0.283123</td>\n      <td>34.09</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>0.283123</td>\n      <td>34.09</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>0.283123</td>\n      <td>34.09</td>\n    </tr>\n  </tbody>\n</table>\n<p>68 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb17c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1585785/1242298558.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.iloc[:,:] = scaler_x.transform(train_set.iloc[:,:])\n",
      "/tmp/ipykernel_1585785/1242298558.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_set.iloc[:,:] = scaler_x.transform(val_set.iloc[:,:])\n",
      "/tmp/ipykernel_1585785/1242298558.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.iloc[:,:] = scaler_y.transform(train_set.iloc[:,:])\n",
      "/tmp/ipykernel_1585785/1242298558.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_set.iloc[:,:] = scaler_y.transform(val_set.iloc[:,:])\n"
     ]
    }
   ],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_set.iloc[:,:])\n",
    "\n",
    "train_set.iloc[:,:] = scaler_x.transform(train_set.iloc[:,:])\n",
    "val_set.iloc[:,:] = scaler_x.transform(val_set.iloc[:,:])\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_set.iloc[:,:])\n",
    "\n",
    "train_set.iloc[:,:] = scaler_y.transform(train_set.iloc[:,:])\n",
    "val_set.iloc[:,:] = scaler_y.transform(val_set.iloc[:,:])\n",
    "\n",
    "trainX, trainY = build_dataset(np.array(train_set), CFG['SEQ_LENGTH'])\n",
    "valX, valY = build_dataset(np.array(val_set), CFG['SEQ_LENGTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef6d2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.0860471 , 0.99215574],\n        [0.09082708, 0.99215574],\n        [0.08126712, 0.99215574],\n        ...,\n        [0.0860471 , 0.99215574],\n        [0.0860471 , 0.99215574],\n        [0.0860471 , 0.99215574]],\n\n       [[0.09082708, 0.99215574],\n        [0.08126712, 0.99215574],\n        [0.08126712, 0.99215574],\n        ...,\n        [0.0860471 , 0.99215574],\n        [0.0860471 , 0.99215574],\n        [0.08126712, 0.99215574]],\n\n       [[0.08126712, 0.99215574],\n        [0.08126712, 0.99215574],\n        [0.0860471 , 0.99275914],\n        ...,\n        [0.0860471 , 0.99215574],\n        [0.08126712, 0.99215574],\n        [0.08126712, 0.99215574]],\n\n       ...,\n\n       [[0.11473071, 0.9993966 ],\n        [0.11473071, 0.9993966 ],\n        [0.11473071, 0.9993966 ],\n        ...,\n        [0.05586148, 0.98796831],\n        [0.05586148, 0.98796831],\n        [0.05586148, 0.98795011]],\n\n       [[0.11473071, 0.9993966 ],\n        [0.11473071, 0.9993966 ],\n        [0.19856521, 0.9879319 ],\n        ...,\n        [0.05586148, 0.98796831],\n        [0.05586148, 0.98795011],\n        [0.0736977 , 0.98795011]],\n\n       [[0.11473071, 0.9993966 ],\n        [0.19856521, 0.9879319 ],\n        [0.23423766, 0.9879319 ],\n        ...,\n        [0.05586148, 0.98795011],\n        [0.0736977 , 0.98795011],\n        [0.05586148, 0.98795011]]])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a877f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.08126712, 0.99215574],\n       [0.08126712, 0.99215574],\n       [0.0621472 , 0.99215574],\n       [0.23423766, 0.99215574],\n       [0.03824357, 0.99155233],\n       [0.        , 0.99155233],\n       [0.        , 0.99155233],\n       [0.00478371, 0.99155233],\n       [0.02390363, 0.9879319 ],\n       [0.01434367, 0.9879319 ],\n       [0.01434367, 0.9879319 ],\n       [0.02390363, 0.9879319 ],\n       [0.02390363, 0.99275914],\n       [0.03346359, 0.99275914],\n       [0.03346359, 0.99275914],\n       [0.03824357, 0.99275914],\n       [0.04302355, 0.99456936],\n       [0.04302355, 0.99456936],\n       [0.03824357, 0.99456936],\n       [0.04302355, 0.99456936],\n       [0.03346359, 0.99577617],\n       [0.03824357, 0.99577617],\n       [0.03824357, 0.99577617],\n       [0.03824357, 0.99577617],\n       [0.04780353, 0.99577617],\n       [0.04780353, 0.99577617],\n       [0.05258724, 0.99577617],\n       [0.05258724, 0.99577617],\n       [0.0621472 , 0.99517276],\n       [0.0621472 , 0.99517276],\n       [0.0621472 , 0.99517276],\n       [0.0621472 , 0.99517276],\n       [0.06692718, 0.99517276],\n       [0.0621472 , 0.99517276],\n       [0.05736722, 0.99517276],\n       [0.0621472 , 0.99517276],\n       [0.0621472 , 0.99637957],\n       [0.0621472 , 0.99637957],\n       [0.0621472 , 0.99637957],\n       [0.0621472 , 0.99637957],\n       [0.07170716, 0.99577617],\n       [0.07170716, 0.99577617],\n       [0.07170716, 0.99577617],\n       [0.08126712, 0.99577617],\n       [0.07648714, 0.99577617],\n       [0.07648714, 0.99577617],\n       [0.09082708, 0.99577617],\n       [0.07648714, 0.99577617],\n       [0.0860471 , 0.99637957],\n       [0.07648714, 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.08126712, 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.0860471 , 0.99637957],\n       [0.09082708, 0.99637957],\n       [0.09082708, 0.99637957],\n       [0.09082708, 0.99698298],\n       [0.09560706, 0.99698298],\n       [0.09560706, 0.99698298],\n       [0.09082708, 0.99698298],\n       [0.09082708, 0.99637957],\n       [0.09082708, 0.99637957],\n       [0.09082708, 0.99637957],\n       [0.09560706, 0.99637957],\n       [0.09560706, 0.99698298],\n       [0.09082708, 0.99698298],\n       [0.08126712, 0.99698298],\n       [0.10517075, 0.99698298],\n       [0.10995073, 0.99758638],\n       [0.05258724, 0.99758638],\n       [0.03824357, 0.99758638],\n       [0.04780353, 0.99758638],\n       [0.04780353, 0.99698298],\n       [0.05258724, 0.99698298],\n       [0.05258724, 0.99698298],\n       [0.05736722, 0.99698298],\n       [0.06692718, 0.99698298],\n       [0.07170716, 0.99698298],\n       [0.07170716, 0.99698298],\n       [0.07648714, 0.99698298],\n       [0.07170716, 0.99698298],\n       [0.08126712, 0.99698298],\n       [0.07170716, 0.99698298],\n       [0.07648714, 0.99698298],\n       [0.07648714, 0.99758638],\n       [0.08126712, 0.99758638],\n       [0.07648714, 0.99758638],\n       [0.08126712, 0.99758638],\n       [0.0860471 , 0.99818979],\n       [0.0860471 , 0.99818979],\n       [0.0860471 , 0.99818979],\n       [0.0860471 , 0.99818979],\n       [0.0860471 , 0.99758638],\n       [0.0860471 , 0.99758638],\n       [0.0860471 , 0.99758638],\n       [0.0860471 , 0.99758638],\n       [0.09082708, 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.0860471 , 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.09560706, 0.99818979],\n       [0.09560706, 0.99818979],\n       [0.09560706, 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.09560706, 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.09082708, 0.99818979],\n       [0.09082708, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09082708, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09560706, 0.99849149],\n       [0.09560706, 0.99818979],\n       [0.10039077, 0.99818979],\n       [0.10995073, 0.99818979],\n       [0.10039077, 0.99818979],\n       [0.10517075, 0.9993966 ],\n       [0.10517075, 0.9993966 ],\n       [0.10517075, 0.9993966 ],\n       [0.10995073, 0.9993966 ],\n       [0.10517075, 0.9993966 ],\n       [0.11473071, 0.9993966 ],\n       [0.10517075, 0.9993966 ],\n       [0.10995073, 0.9993966 ],\n       [0.10517075, 0.9993966 ],\n       [0.11473071, 0.9993966 ],\n       [0.10995073, 0.9993966 ],\n       [0.10995073, 0.9993966 ],\n       [0.11473071, 0.99849149],\n       [0.10995073, 0.99849149],\n       [0.11951069, 0.99849149],\n       [0.11473071, 0.99849149],\n       [0.11473071, 1.        ],\n       [0.11473071, 1.        ],\n       [0.11473071, 1.        ],\n       [0.11951069, 1.        ],\n       [0.10995073, 0.9993966 ],\n       [0.11473071, 0.9993966 ],\n       [0.11473071, 0.9993966 ],\n       [0.11473071, 0.9993966 ],\n       [0.19856521, 0.9879319 ],\n       [0.23423766, 0.9879319 ],\n       [0.19856521, 0.9879319 ],\n       [0.19856521, 0.9879319 ],\n       [0.21640143, 0.98796831],\n       [0.21640143, 0.98796831],\n       [0.19856521, 0.98796831],\n       [0.21640143, 0.98796831],\n       [0.18072898, 0.98795011],\n       [0.14505653, 0.98795011],\n       [0.0736977 , 0.98795011],\n       [0.05586148, 0.98795011],\n       [0.09153393, 0.98796831],\n       [0.0736977 , 0.98796831],\n       [0.05586148, 0.98796831],\n       [0.05586148, 0.98796831],\n       [0.05586148, 0.98795011],\n       [0.0736977 , 0.98795011],\n       [0.05586148, 0.98795011],\n       [0.05586148, 0.98795011]])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7425fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tensor = torch.FloatTensor(trainX).to(device)\n",
    "trainY_tensor = torch.FloatTensor(trainY).to(device)\n",
    "\n",
    "valX_tensor = torch.FloatTensor(valX).to(device)\n",
    "valY_tensor = torch.FloatTensor(valY).to(device)\n",
    "\n",
    "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7f358ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = LSTM(CFG['INPUT_DIM'], CFG['HIDDEN_DIM'], CFG['SEQ_LENGTH'], CFG['OUTPUT_DIM'], 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aba437fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df, epochs, lr, verbose, patience):\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_history = np.zeros(epochs)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_df)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_df):\n",
    "            x_train, y_train = samples\n",
    "            model.reset_hidden_state()\n",
    "            print(x_train.shape)\n",
    "            outputs = model(x_train) # h(x)\n",
    "            loss = criterion(outputs, y_train) # h(y)\n",
    "            print('----------------')\n",
    "            print(outputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_cost += loss/total_batch\n",
    "        train_history[epoch] = avg_cost\n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch ', '%02d' % (epoch), 'Train Loss: ', '{:.4f}'.format(avg_cost))\n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            if train_history[epoch-patience] < train_history[epoch]:\n",
    "                print('\\n Early Stopping')\n",
    "                break\n",
    "    return model.eval(), train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5de81ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1847],\n",
      "        [-0.1841],\n",
      "        [-0.1845],\n",
      "        [-0.1849],\n",
      "        [-0.1852],\n",
      "        [-0.1854],\n",
      "        [-0.1856],\n",
      "        [-0.1858],\n",
      "        [-0.1859],\n",
      "        [-0.1859],\n",
      "        [-0.1856],\n",
      "        [-0.1854],\n",
      "        [-0.1853],\n",
      "        [-0.1852],\n",
      "        [-0.1851],\n",
      "        [-0.1850],\n",
      "        [-0.1849],\n",
      "        [-0.1849],\n",
      "        [-0.1849],\n",
      "        [-0.1848],\n",
      "        [-0.1848],\n",
      "        [-0.1848],\n",
      "        [-0.1848],\n",
      "        [-0.1847],\n",
      "        [-0.1847],\n",
      "        [-0.1847],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1845],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1845],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1843],\n",
      "        [-0.1843],\n",
      "        [-0.1843],\n",
      "        [-0.1843],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1841],\n",
      "        [-0.1842],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1841],\n",
      "        [-0.1842],\n",
      "        [-0.1843],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.1843],\n",
      "        [-0.1843],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch  00 Train Loss:  0.7284\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1840],\n",
      "        [-0.1834],\n",
      "        [-0.1839],\n",
      "        [-0.1842],\n",
      "        [-0.1845],\n",
      "        [-0.1847],\n",
      "        [-0.1849],\n",
      "        [-0.1851],\n",
      "        [-0.1852],\n",
      "        [-0.1852],\n",
      "        [-0.1849],\n",
      "        [-0.1847],\n",
      "        [-0.1846],\n",
      "        [-0.1846],\n",
      "        [-0.1844],\n",
      "        [-0.1843],\n",
      "        [-0.1843],\n",
      "        [-0.1842],\n",
      "        [-0.1842],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1841],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1840],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1839],\n",
      "        [-0.1838],\n",
      "        [-0.1838],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1836],\n",
      "        [-0.1836],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1832],\n",
      "        [-0.1834],\n",
      "        [-0.1835],\n",
      "        [-0.1836],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1838],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1836],\n",
      "        [-0.1836],\n",
      "        [-0.1836],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1833],\n",
      "        [-0.1827],\n",
      "        [-0.1831],\n",
      "        [-0.1835],\n",
      "        [-0.1838],\n",
      "        [-0.1840],\n",
      "        [-0.1842],\n",
      "        [-0.1844],\n",
      "        [-0.1845],\n",
      "        [-0.1845],\n",
      "        [-0.1842],\n",
      "        [-0.1840],\n",
      "        [-0.1839],\n",
      "        [-0.1838],\n",
      "        [-0.1837],\n",
      "        [-0.1836],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1835],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1834],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1833],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1831],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1832],\n",
      "        [-0.1831],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1829],\n",
      "        [-0.1829],\n",
      "        [-0.1829],\n",
      "        [-0.1829],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1827],\n",
      "        [-0.1828],\n",
      "        [-0.1829],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1829],\n",
      "        [-0.1829],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1826],\n",
      "        [-0.1820],\n",
      "        [-0.1824],\n",
      "        [-0.1828],\n",
      "        [-0.1831],\n",
      "        [-0.1832],\n",
      "        [-0.1835],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1835],\n",
      "        [-0.1833],\n",
      "        [-0.1832],\n",
      "        [-0.1831],\n",
      "        [-0.1829],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1827],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1826],\n",
      "        [-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1825],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1822],\n",
      "        [-0.1822],\n",
      "        [-0.1822],\n",
      "        [-0.1821],\n",
      "        [-0.1822],\n",
      "        [-0.1821],\n",
      "        [-0.1821],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1819],\n",
      "        [-0.1818],\n",
      "        [-0.1817],\n",
      "        [-0.1819],\n",
      "        [-0.1821],\n",
      "        [-0.1822],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1822],\n",
      "        [-0.1822],\n",
      "        [-0.1821],\n",
      "        [-0.1821],\n",
      "        [-0.1821],\n",
      "        [-0.1820],\n",
      "        [-0.1821],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1818]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1819],\n",
      "        [-0.1813],\n",
      "        [-0.1817],\n",
      "        [-0.1821],\n",
      "        [-0.1824],\n",
      "        [-0.1826],\n",
      "        [-0.1828],\n",
      "        [-0.1830],\n",
      "        [-0.1831],\n",
      "        [-0.1831],\n",
      "        [-0.1828],\n",
      "        [-0.1826],\n",
      "        [-0.1825],\n",
      "        [-0.1824],\n",
      "        [-0.1823],\n",
      "        [-0.1822],\n",
      "        [-0.1821],\n",
      "        [-0.1821],\n",
      "        [-0.1821],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1820],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1819],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1818],\n",
      "        [-0.1817],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1815],\n",
      "        [-0.1815],\n",
      "        [-0.1815],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1813],\n",
      "        [-0.1814],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1811],\n",
      "        [-0.1811],\n",
      "        [-0.1813],\n",
      "        [-0.1814],\n",
      "        [-0.1815],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1817],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1815],\n",
      "        [-0.1815],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1811],\n",
      "        [-0.1805],\n",
      "        [-0.1810],\n",
      "        [-0.1813],\n",
      "        [-0.1816],\n",
      "        [-0.1818],\n",
      "        [-0.1820],\n",
      "        [-0.1822],\n",
      "        [-0.1823],\n",
      "        [-0.1823],\n",
      "        [-0.1821],\n",
      "        [-0.1819],\n",
      "        [-0.1817],\n",
      "        [-0.1817],\n",
      "        [-0.1815],\n",
      "        [-0.1814],\n",
      "        [-0.1814],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1813],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1812],\n",
      "        [-0.1811],\n",
      "        [-0.1811],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1809],\n",
      "        [-0.1809],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1808],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1803],\n",
      "        [-0.1805],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1808],\n",
      "        [-0.1809],\n",
      "        [-0.1809],\n",
      "        [-0.1809],\n",
      "        [-0.1808],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1804],\n",
      "        [-0.1805],\n",
      "        [-0.1798],\n",
      "        [-0.1803],\n",
      "        [-0.1807],\n",
      "        [-0.1810],\n",
      "        [-0.1811],\n",
      "        [-0.1813],\n",
      "        [-0.1815],\n",
      "        [-0.1816],\n",
      "        [-0.1816],\n",
      "        [-0.1814],\n",
      "        [-0.1812],\n",
      "        [-0.1811],\n",
      "        [-0.1810],\n",
      "        [-0.1808],\n",
      "        [-0.1807],\n",
      "        [-0.1807],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1806],\n",
      "        [-0.1805],\n",
      "        [-0.1805],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1804],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1803],\n",
      "        [-0.1802],\n",
      "        [-0.1802],\n",
      "        [-0.1802],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1800],\n",
      "        [-0.1800],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1799],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1798],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1798],\n",
      "        [-0.1797],\n",
      "        [-0.1796],\n",
      "        [-0.1798],\n",
      "        [-0.1800],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1802],\n",
      "        [-0.1802],\n",
      "        [-0.1802],\n",
      "        [-0.1801],\n",
      "        [-0.1801],\n",
      "        [-0.1800],\n",
      "        [-0.1800],\n",
      "        [-0.1800],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1797],\n",
      "        [-0.1797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1797],\n",
      "        [-0.1791],\n",
      "        [-0.1796],\n",
      "        [-0.1800],\n",
      "        [-0.1802],\n",
      "        [-0.1804],\n",
      "        [-0.1806],\n",
      "        [-0.1808],\n",
      "        [-0.1809],\n",
      "        [-0.1809],\n",
      "        [-0.1807],\n",
      "        [-0.1805],\n",
      "        [-0.1804],\n",
      "        [-0.1803],\n",
      "        [-0.1801],\n",
      "        [-0.1800],\n",
      "        [-0.1800],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1799],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1797],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1795],\n",
      "        [-0.1795],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1793],\n",
      "        [-0.1793],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1789],\n",
      "        [-0.1791],\n",
      "        [-0.1793],\n",
      "        [-0.1793],\n",
      "        [-0.1794],\n",
      "        [-0.1795],\n",
      "        [-0.1795],\n",
      "        [-0.1795],\n",
      "        [-0.1794],\n",
      "        [-0.1793],\n",
      "        [-0.1793],\n",
      "        [-0.1793],\n",
      "        [-0.1793],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1789],\n",
      "        [-0.1789],\n",
      "        [-0.1789],\n",
      "        [-0.1790],\n",
      "        [-0.1783],\n",
      "        [-0.1788],\n",
      "        [-0.1792],\n",
      "        [-0.1795],\n",
      "        [-0.1797],\n",
      "        [-0.1799],\n",
      "        [-0.1801],\n",
      "        [-0.1802],\n",
      "        [-0.1802],\n",
      "        [-0.1799],\n",
      "        [-0.1797],\n",
      "        [-0.1796],\n",
      "        [-0.1795],\n",
      "        [-0.1794],\n",
      "        [-0.1793],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1792],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1791],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1790],\n",
      "        [-0.1789],\n",
      "        [-0.1789],\n",
      "        [-0.1789],\n",
      "        [-0.1789],\n",
      "        [-0.1788],\n",
      "        [-0.1788],\n",
      "        [-0.1789],\n",
      "        [-0.1788],\n",
      "        [-0.1788],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1786],\n",
      "        [-0.1786],\n",
      "        [-0.1786],\n",
      "        [-0.1785],\n",
      "        [-0.1786],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1782],\n",
      "        [-0.1781],\n",
      "        [-0.1783],\n",
      "        [-0.1785],\n",
      "        [-0.1786],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1786],\n",
      "        [-0.1786],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1782]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1783],\n",
      "        [-0.1776],\n",
      "        [-0.1781],\n",
      "        [-0.1785],\n",
      "        [-0.1788],\n",
      "        [-0.1790],\n",
      "        [-0.1792],\n",
      "        [-0.1794],\n",
      "        [-0.1795],\n",
      "        [-0.1795],\n",
      "        [-0.1792],\n",
      "        [-0.1790],\n",
      "        [-0.1789],\n",
      "        [-0.1788],\n",
      "        [-0.1787],\n",
      "        [-0.1786],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1785],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1784],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1783],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1782],\n",
      "        [-0.1781],\n",
      "        [-0.1781],\n",
      "        [-0.1782],\n",
      "        [-0.1781],\n",
      "        [-0.1781],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1779],\n",
      "        [-0.1779],\n",
      "        [-0.1779],\n",
      "        [-0.1778],\n",
      "        [-0.1779],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1775],\n",
      "        [-0.1775],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1775],\n",
      "        [-0.1775],\n",
      "        [-0.1776],\n",
      "        [-0.1775],\n",
      "        [-0.1774],\n",
      "        [-0.1776],\n",
      "        [-0.1778],\n",
      "        [-0.1779],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.1779],\n",
      "        [-0.1779],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1775]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1774],\n",
      "        [-0.1775],\n",
      "        [-0.1775],\n",
      "        [-0.1776],\n",
      "        [-0.1769],\n",
      "        [-0.1774],\n",
      "        [-0.1778],\n",
      "        [-0.1781],\n",
      "        [-0.1783],\n",
      "        [-0.1785],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1787],\n",
      "        [-0.1785],\n",
      "        [-0.1783],\n",
      "        [-0.1782],\n",
      "        [-0.1781],\n",
      "        [-0.1779],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.1776],\n",
      "        [-0.1776],\n",
      "        [-0.1775],\n",
      "        [-0.1775],\n",
      "        [-0.1775],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1774],\n",
      "        [-0.1773],\n",
      "        [-0.1773],\n",
      "        [-0.1773],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1771],\n",
      "        [-0.1771],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1770],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1767],\n",
      "        [-0.1769],\n",
      "        [-0.1771],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1773],\n",
      "        [-0.1773],\n",
      "        [-0.1773],\n",
      "        [-0.1772],\n",
      "        [-0.1772],\n",
      "        [-0.1771],\n",
      "        [-0.1771],\n",
      "        [-0.1771],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1768]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1767],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1769],\n",
      "        [-0.1762],\n",
      "        [-0.1767],\n",
      "        [-0.1771],\n",
      "        [-0.1774],\n",
      "        [-0.1776],\n",
      "        [-0.1778],\n",
      "        [-0.1780],\n",
      "        [-0.1781],\n",
      "        [-0.1781],\n",
      "        [-0.1778],\n",
      "        [-0.1776],\n",
      "        [-0.1775],\n",
      "        [-0.1774],\n",
      "        [-0.1772],\n",
      "        [-0.1771],\n",
      "        [-0.1771],\n",
      "        [-0.1771],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1770],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1768],\n",
      "        [-0.1767],\n",
      "        [-0.1767],\n",
      "        [-0.1767],\n",
      "        [-0.1767],\n",
      "        [-0.1767],\n",
      "        [-0.1767],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1765],\n",
      "        [-0.1765],\n",
      "        [-0.1765],\n",
      "        [-0.1765],\n",
      "        [-0.1764],\n",
      "        [-0.1764],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1762],\n",
      "        [-0.1761],\n",
      "        [-0.1760],\n",
      "        [-0.1762],\n",
      "        [-0.1764],\n",
      "        [-0.1765],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1765],\n",
      "        [-0.1765],\n",
      "        [-0.1764],\n",
      "        [-0.1764],\n",
      "        [-0.1764],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1761],\n",
      "        [-0.1761]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1761],\n",
      "        [-0.1754],\n",
      "        [-0.1759],\n",
      "        [-0.1764],\n",
      "        [-0.1767],\n",
      "        [-0.1768],\n",
      "        [-0.1770],\n",
      "        [-0.1772],\n",
      "        [-0.1773],\n",
      "        [-0.1773],\n",
      "        [-0.1771],\n",
      "        [-0.1769],\n",
      "        [-0.1768],\n",
      "        [-0.1767],\n",
      "        [-0.1765],\n",
      "        [-0.1764],\n",
      "        [-0.1764],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1763],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1762],\n",
      "        [-0.1761],\n",
      "        [-0.1761],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.1759],\n",
      "        [-0.1759],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1757],\n",
      "        [-0.1757],\n",
      "        [-0.1757],\n",
      "        [-0.1757],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1753],\n",
      "        [-0.1752],\n",
      "        [-0.1755],\n",
      "        [-0.1757],\n",
      "        [-0.1757],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1759],\n",
      "        [-0.1758],\n",
      "        [-0.1758],\n",
      "        [-0.1757],\n",
      "        [-0.1757],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1753],\n",
      "        [-0.1753],\n",
      "        [-0.1753],\n",
      "        [-0.1754],\n",
      "        [-0.1747],\n",
      "        [-0.1752],\n",
      "        [-0.1756],\n",
      "        [-0.1759],\n",
      "        [-0.1761],\n",
      "        [-0.1763],\n",
      "        [-0.1765],\n",
      "        [-0.1766],\n",
      "        [-0.1766],\n",
      "        [-0.1763],\n",
      "        [-0.1761],\n",
      "        [-0.1760],\n",
      "        [-0.1759],\n",
      "        [-0.1758],\n",
      "        [-0.1757],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1756],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1755],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1754],\n",
      "        [-0.1753],\n",
      "        [-0.1753],\n",
      "        [-0.1753],\n",
      "        [-0.1753],\n",
      "        [-0.1752],\n",
      "        [-0.1752],\n",
      "        [-0.1753],\n",
      "        [-0.1752],\n",
      "        [-0.1752],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1750],\n",
      "        [-0.1750],\n",
      "        [-0.1750],\n",
      "        [-0.1749],\n",
      "        [-0.1750],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1747],\n",
      "        [-0.1746],\n",
      "        [-0.1745],\n",
      "        [-0.1747],\n",
      "        [-0.1749],\n",
      "        [-0.1750],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1750],\n",
      "        [-0.1750],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1747],\n",
      "        [-0.1740],\n",
      "        [-0.1745],\n",
      "        [-0.1749],\n",
      "        [-0.1752],\n",
      "        [-0.1754],\n",
      "        [-0.1756],\n",
      "        [-0.1758],\n",
      "        [-0.1759],\n",
      "        [-0.1759],\n",
      "        [-0.1756],\n",
      "        [-0.1754],\n",
      "        [-0.1753],\n",
      "        [-0.1752],\n",
      "        [-0.1751],\n",
      "        [-0.1750],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1749],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1748],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1747],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1746],\n",
      "        [-0.1745],\n",
      "        [-0.1745],\n",
      "        [-0.1746],\n",
      "        [-0.1745],\n",
      "        [-0.1745],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1743],\n",
      "        [-0.1743],\n",
      "        [-0.1743],\n",
      "        [-0.1742],\n",
      "        [-0.1743],\n",
      "        [-0.1742],\n",
      "        [-0.1742],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1740],\n",
      "        [-0.1739],\n",
      "        [-0.1738],\n",
      "        [-0.1740],\n",
      "        [-0.1742],\n",
      "        [-0.1743],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1744],\n",
      "        [-0.1743],\n",
      "        [-0.1743],\n",
      "        [-0.1742],\n",
      "        [-0.1742],\n",
      "        [-0.1741],\n",
      "        [-0.1742],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1738],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1740],\n",
      "        [-0.1733],\n",
      "        [-0.1738],\n",
      "        [-0.1742],\n",
      "        [-0.1745],\n",
      "        [-0.1747],\n",
      "        [-0.1749],\n",
      "        [-0.1751],\n",
      "        [-0.1752],\n",
      "        [-0.1752],\n",
      "        [-0.1749],\n",
      "        [-0.1747],\n",
      "        [-0.1746],\n",
      "        [-0.1745],\n",
      "        [-0.1743],\n",
      "        [-0.1742],\n",
      "        [-0.1742],\n",
      "        [-0.1742],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1741],\n",
      "        [-0.1740],\n",
      "        [-0.1740],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1739],\n",
      "        [-0.1738],\n",
      "        [-0.1738],\n",
      "        [-0.1738],\n",
      "        [-0.1738],\n",
      "        [-0.1738],\n",
      "        [-0.1738],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1735],\n",
      "        [-0.1735],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1733],\n",
      "        [-0.1734],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1733],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1733],\n",
      "        [-0.1732],\n",
      "        [-0.1731],\n",
      "        [-0.1733],\n",
      "        [-0.1735],\n",
      "        [-0.1736],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1735],\n",
      "        [-0.1735],\n",
      "        [-0.1735],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1732],\n",
      "        [-0.1732]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1731],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1733],\n",
      "        [-0.1726],\n",
      "        [-0.1731],\n",
      "        [-0.1735],\n",
      "        [-0.1738],\n",
      "        [-0.1740],\n",
      "        [-0.1742],\n",
      "        [-0.1744],\n",
      "        [-0.1745],\n",
      "        [-0.1745],\n",
      "        [-0.1742],\n",
      "        [-0.1740],\n",
      "        [-0.1739],\n",
      "        [-0.1738],\n",
      "        [-0.1737],\n",
      "        [-0.1736],\n",
      "        [-0.1735],\n",
      "        [-0.1735],\n",
      "        [-0.1735],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1734],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1733],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1732],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1729],\n",
      "        [-0.1729],\n",
      "        [-0.1729],\n",
      "        [-0.1728],\n",
      "        [-0.1728],\n",
      "        [-0.1727],\n",
      "        [-0.1728],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1726],\n",
      "        [-0.1725],\n",
      "        [-0.1724],\n",
      "        [-0.1726],\n",
      "        [-0.1728],\n",
      "        [-0.1729],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1729],\n",
      "        [-0.1729],\n",
      "        [-0.1728],\n",
      "        [-0.1728],\n",
      "        [-0.1728],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1725],\n",
      "        [-0.1725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1725],\n",
      "        [-0.1718],\n",
      "        [-0.1723],\n",
      "        [-0.1727],\n",
      "        [-0.1730],\n",
      "        [-0.1732],\n",
      "        [-0.1734],\n",
      "        [-0.1736],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1734],\n",
      "        [-0.1732],\n",
      "        [-0.1731],\n",
      "        [-0.1730],\n",
      "        [-0.1729],\n",
      "        [-0.1728],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1727],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1726],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1723],\n",
      "        [-0.1723],\n",
      "        [-0.1724],\n",
      "        [-0.1723],\n",
      "        [-0.1723],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1721],\n",
      "        [-0.1721],\n",
      "        [-0.1721],\n",
      "        [-0.1720],\n",
      "        [-0.1721],\n",
      "        [-0.1720],\n",
      "        [-0.1720],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1716],\n",
      "        [-0.1718],\n",
      "        [-0.1720],\n",
      "        [-0.1721],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1722],\n",
      "        [-0.1721],\n",
      "        [-0.1721],\n",
      "        [-0.1720],\n",
      "        [-0.1720],\n",
      "        [-0.1719],\n",
      "        [-0.1720],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1717]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1718],\n",
      "        [-0.1711],\n",
      "        [-0.1716],\n",
      "        [-0.1720],\n",
      "        [-0.1724],\n",
      "        [-0.1725],\n",
      "        [-0.1727],\n",
      "        [-0.1729],\n",
      "        [-0.1730],\n",
      "        [-0.1730],\n",
      "        [-0.1728],\n",
      "        [-0.1725],\n",
      "        [-0.1724],\n",
      "        [-0.1724],\n",
      "        [-0.1722],\n",
      "        [-0.1721],\n",
      "        [-0.1720],\n",
      "        [-0.1720],\n",
      "        [-0.1720],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1719],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1716],\n",
      "        [-0.1716],\n",
      "        [-0.1717],\n",
      "        [-0.1717],\n",
      "        [-0.1716],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1714],\n",
      "        [-0.1714],\n",
      "        [-0.1714],\n",
      "        [-0.1713],\n",
      "        [-0.1714],\n",
      "        [-0.1713],\n",
      "        [-0.1713],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1709],\n",
      "        [-0.1711],\n",
      "        [-0.1713],\n",
      "        [-0.1714],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1715],\n",
      "        [-0.1714],\n",
      "        [-0.1714],\n",
      "        [-0.1713],\n",
      "        [-0.1713],\n",
      "        [-0.1712],\n",
      "        [-0.1713],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1710]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1709],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1711],\n",
      "        [-0.1704],\n",
      "        [-0.1709],\n",
      "        [-0.1713],\n",
      "        [-0.1716],\n",
      "        [-0.1718],\n",
      "        [-0.1720],\n",
      "        [-0.1722],\n",
      "        [-0.1723],\n",
      "        [-0.1723],\n",
      "        [-0.1720],\n",
      "        [-0.1718],\n",
      "        [-0.1717],\n",
      "        [-0.1716],\n",
      "        [-0.1715],\n",
      "        [-0.1714],\n",
      "        [-0.1713],\n",
      "        [-0.1713],\n",
      "        [-0.1713],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1712],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1710],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1707],\n",
      "        [-0.1707],\n",
      "        [-0.1707],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1704],\n",
      "        [-0.1704],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1704],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1702],\n",
      "        [-0.1704],\n",
      "        [-0.1706],\n",
      "        [-0.1707],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1708],\n",
      "        [-0.1707],\n",
      "        [-0.1707],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1705],\n",
      "        [-0.1706],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1704],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1703],\n",
      "        [-0.1704],\n",
      "        [-0.1696],\n",
      "        [-0.1702],\n",
      "        [-0.1706],\n",
      "        [-0.1709],\n",
      "        [-0.1711],\n",
      "        [-0.1713],\n",
      "        [-0.1715],\n",
      "        [-0.1716],\n",
      "        [-0.1716],\n",
      "        [-0.1713],\n",
      "        [-0.1711],\n",
      "        [-0.1710],\n",
      "        [-0.1709],\n",
      "        [-0.1707],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1706],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1705],\n",
      "        [-0.1704],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1703],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1702],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1700],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1695],\n",
      "        [-0.1694],\n",
      "        [-0.1697],\n",
      "        [-0.1699],\n",
      "        [-0.1700],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1700],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch  20 Train Loss:  0.7080\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1695],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1697],\n",
      "        [-0.1689],\n",
      "        [-0.1695],\n",
      "        [-0.1699],\n",
      "        [-0.1702],\n",
      "        [-0.1704],\n",
      "        [-0.1706],\n",
      "        [-0.1708],\n",
      "        [-0.1709],\n",
      "        [-0.1709],\n",
      "        [-0.1706],\n",
      "        [-0.1704],\n",
      "        [-0.1703],\n",
      "        [-0.1702],\n",
      "        [-0.1701],\n",
      "        [-0.1700],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1699],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1698],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1697],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1695],\n",
      "        [-0.1695],\n",
      "        [-0.1695],\n",
      "        [-0.1695],\n",
      "        [-0.1695],\n",
      "        [-0.1695],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1693],\n",
      "        [-0.1693],\n",
      "        [-0.1693],\n",
      "        [-0.1692],\n",
      "        [-0.1692],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1690],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1690],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1690],\n",
      "        [-0.1689],\n",
      "        [-0.1688],\n",
      "        [-0.1690],\n",
      "        [-0.1692],\n",
      "        [-0.1693],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1693],\n",
      "        [-0.1693],\n",
      "        [-0.1692],\n",
      "        [-0.1692],\n",
      "        [-0.1692],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1689],\n",
      "        [-0.1689]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1687],\n",
      "        [-0.1688],\n",
      "        [-0.1688],\n",
      "        [-0.1689],\n",
      "        [-0.1681],\n",
      "        [-0.1687],\n",
      "        [-0.1691],\n",
      "        [-0.1695],\n",
      "        [-0.1696],\n",
      "        [-0.1698],\n",
      "        [-0.1700],\n",
      "        [-0.1701],\n",
      "        [-0.1701],\n",
      "        [-0.1699],\n",
      "        [-0.1696],\n",
      "        [-0.1695],\n",
      "        [-0.1694],\n",
      "        [-0.1693],\n",
      "        [-0.1692],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1691],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1690],\n",
      "        [-0.1689],\n",
      "        [-0.1689],\n",
      "        [-0.1688],\n",
      "        [-0.1688],\n",
      "        [-0.1688],\n",
      "        [-0.1688],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1685],\n",
      "        [-0.1685],\n",
      "        [-0.1685],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1680],\n",
      "        [-0.1682],\n",
      "        [-0.1684],\n",
      "        [-0.1685],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1686],\n",
      "        [-0.1685],\n",
      "        [-0.1685],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1683],\n",
      "        [-0.1684],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1681]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1682],\n",
      "        [-0.1674],\n",
      "        [-0.1680],\n",
      "        [-0.1685],\n",
      "        [-0.1688],\n",
      "        [-0.1690],\n",
      "        [-0.1692],\n",
      "        [-0.1693],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.1692],\n",
      "        [-0.1690],\n",
      "        [-0.1688],\n",
      "        [-0.1688],\n",
      "        [-0.1686],\n",
      "        [-0.1685],\n",
      "        [-0.1685],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1684],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1683],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1680],\n",
      "        [-0.1680],\n",
      "        [-0.1681],\n",
      "        [-0.1681],\n",
      "        [-0.1680],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1678],\n",
      "        [-0.1678],\n",
      "        [-0.1678],\n",
      "        [-0.1677],\n",
      "        [-0.1678],\n",
      "        [-0.1677],\n",
      "        [-0.1677],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1673],\n",
      "        [-0.1675],\n",
      "        [-0.1677],\n",
      "        [-0.1678],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1679],\n",
      "        [-0.1678],\n",
      "        [-0.1678],\n",
      "        [-0.1677],\n",
      "        [-0.1677],\n",
      "        [-0.1676],\n",
      "        [-0.1677],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1674]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1673],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1675],\n",
      "        [-0.1667],\n",
      "        [-0.1673],\n",
      "        [-0.1677],\n",
      "        [-0.1681],\n",
      "        [-0.1682],\n",
      "        [-0.1684],\n",
      "        [-0.1686],\n",
      "        [-0.1687],\n",
      "        [-0.1687],\n",
      "        [-0.1685],\n",
      "        [-0.1682],\n",
      "        [-0.1681],\n",
      "        [-0.1680],\n",
      "        [-0.1679],\n",
      "        [-0.1678],\n",
      "        [-0.1677],\n",
      "        [-0.1677],\n",
      "        [-0.1677],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1676],\n",
      "        [-0.1675],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1671],\n",
      "        [-0.1671],\n",
      "        [-0.1671],\n",
      "        [-0.1670],\n",
      "        [-0.1670],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1668],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1666],\n",
      "        [-0.1668],\n",
      "        [-0.1670],\n",
      "        [-0.1671],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1672],\n",
      "        [-0.1671],\n",
      "        [-0.1671],\n",
      "        [-0.1670],\n",
      "        [-0.1670],\n",
      "        [-0.1670],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1667]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1667],\n",
      "        [-0.1660],\n",
      "        [-0.1665],\n",
      "        [-0.1670],\n",
      "        [-0.1673],\n",
      "        [-0.1675],\n",
      "        [-0.1677],\n",
      "        [-0.1679],\n",
      "        [-0.1680],\n",
      "        [-0.1680],\n",
      "        [-0.1677],\n",
      "        [-0.1675],\n",
      "        [-0.1674],\n",
      "        [-0.1673],\n",
      "        [-0.1671],\n",
      "        [-0.1670],\n",
      "        [-0.1670],\n",
      "        [-0.1670],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1669],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1666],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1659],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1659],\n",
      "        [-0.1658],\n",
      "        [-0.1661],\n",
      "        [-0.1663],\n",
      "        [-0.1664],\n",
      "        [-0.1664],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.1664],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1659],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1661],\n",
      "        [-0.1653],\n",
      "        [-0.1659],\n",
      "        [-0.1663],\n",
      "        [-0.1667],\n",
      "        [-0.1668],\n",
      "        [-0.1670],\n",
      "        [-0.1672],\n",
      "        [-0.1673],\n",
      "        [-0.1673],\n",
      "        [-0.1671],\n",
      "        [-0.1668],\n",
      "        [-0.1667],\n",
      "        [-0.1666],\n",
      "        [-0.1665],\n",
      "        [-0.1664],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1663],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1662],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1661],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1660],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1657],\n",
      "        [-0.1657],\n",
      "        [-0.1657],\n",
      "        [-0.1657],\n",
      "        [-0.1656],\n",
      "        [-0.1656],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1655],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1652],\n",
      "        [-0.1651],\n",
      "        [-0.1654],\n",
      "        [-0.1656],\n",
      "        [-0.1657],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1657],\n",
      "        [-0.1657],\n",
      "        [-0.1656],\n",
      "        [-0.1656],\n",
      "        [-0.1656],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1653]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1651],\n",
      "        [-0.1652],\n",
      "        [-0.1652],\n",
      "        [-0.1653],\n",
      "        [-0.1645],\n",
      "        [-0.1651],\n",
      "        [-0.1656],\n",
      "        [-0.1659],\n",
      "        [-0.1661],\n",
      "        [-0.1663],\n",
      "        [-0.1664],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.1663],\n",
      "        [-0.1661],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.1657],\n",
      "        [-0.1656],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1654],\n",
      "        [-0.1653],\n",
      "        [-0.1653],\n",
      "        [-0.1652],\n",
      "        [-0.1652],\n",
      "        [-0.1652],\n",
      "        [-0.1652],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1649],\n",
      "        [-0.1649],\n",
      "        [-0.1649],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1647],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1644],\n",
      "        [-0.1646],\n",
      "        [-0.1648],\n",
      "        [-0.1649],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.1649],\n",
      "        [-0.1649],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1645]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1644],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1646],\n",
      "        [-0.1638],\n",
      "        [-0.1644],\n",
      "        [-0.1649],\n",
      "        [-0.1652],\n",
      "        [-0.1654],\n",
      "        [-0.1656],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.1656],\n",
      "        [-0.1654],\n",
      "        [-0.1653],\n",
      "        [-0.1652],\n",
      "        [-0.1650],\n",
      "        [-0.1649],\n",
      "        [-0.1649],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1647],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1645],\n",
      "        [-0.1644],\n",
      "        [-0.1644],\n",
      "        [-0.1645],\n",
      "        [-0.1644],\n",
      "        [-0.1644],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1642],\n",
      "        [-0.1642],\n",
      "        [-0.1642],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1637],\n",
      "        [-0.1639],\n",
      "        [-0.1641],\n",
      "        [-0.1642],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.1642],\n",
      "        [-0.1642],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1640],\n",
      "        [-0.1641],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1638]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1638],\n",
      "        [-0.1639],\n",
      "        [-0.1631],\n",
      "        [-0.1637],\n",
      "        [-0.1641],\n",
      "        [-0.1645],\n",
      "        [-0.1647],\n",
      "        [-0.1649],\n",
      "        [-0.1650],\n",
      "        [-0.1651],\n",
      "        [-0.1651],\n",
      "        [-0.1649],\n",
      "        [-0.1646],\n",
      "        [-0.1645],\n",
      "        [-0.1644],\n",
      "        [-0.1643],\n",
      "        [-0.1642],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1641],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1638],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1635],\n",
      "        [-0.1635],\n",
      "        [-0.1635],\n",
      "        [-0.1635],\n",
      "        [-0.1635],\n",
      "        [-0.1634],\n",
      "        [-0.1634],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1630],\n",
      "        [-0.1629],\n",
      "        [-0.1632],\n",
      "        [-0.1634],\n",
      "        [-0.1635],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1636],\n",
      "        [-0.1635],\n",
      "        [-0.1635],\n",
      "        [-0.1634],\n",
      "        [-0.1634],\n",
      "        [-0.1634],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1631],\n",
      "        [-0.1623],\n",
      "        [-0.1629],\n",
      "        [-0.1634],\n",
      "        [-0.1637],\n",
      "        [-0.1639],\n",
      "        [-0.1641],\n",
      "        [-0.1643],\n",
      "        [-0.1644],\n",
      "        [-0.1644],\n",
      "        [-0.1641],\n",
      "        [-0.1639],\n",
      "        [-0.1638],\n",
      "        [-0.1637],\n",
      "        [-0.1635],\n",
      "        [-0.1634],\n",
      "        [-0.1634],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1633],\n",
      "        [-0.1632],\n",
      "        [-0.1632],\n",
      "        [-0.1631],\n",
      "        [-0.1631],\n",
      "        [-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1629],\n",
      "        [-0.1629],\n",
      "        [-0.1630],\n",
      "        [-0.1630],\n",
      "        [-0.1629],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1627],\n",
      "        [-0.1627],\n",
      "        [-0.1627],\n",
      "        [-0.1626],\n",
      "        [-0.1627],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1624],\n",
      "        [-0.1623],\n",
      "        [-0.1622],\n",
      "        [-0.1624],\n",
      "        [-0.1627],\n",
      "        [-0.1627],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1629],\n",
      "        [-0.1628],\n",
      "        [-0.1628],\n",
      "        [-0.1627],\n",
      "        [-0.1627],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1625],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1623],\n",
      "        [-0.1623]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1624],\n",
      "        [-0.1616],\n",
      "        [-0.1622],\n",
      "        [-0.1627],\n",
      "        [-0.1630],\n",
      "        [-0.1632],\n",
      "        [-0.1634],\n",
      "        [-0.1636],\n",
      "        [-0.1637],\n",
      "        [-0.1637],\n",
      "        [-0.1634],\n",
      "        [-0.1632],\n",
      "        [-0.1631],\n",
      "        [-0.1630],\n",
      "        [-0.1628],\n",
      "        [-0.1627],\n",
      "        [-0.1627],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1626],\n",
      "        [-0.1625],\n",
      "        [-0.1625],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1622],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1623],\n",
      "        [-0.1622],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1620],\n",
      "        [-0.1620],\n",
      "        [-0.1620],\n",
      "        [-0.1619],\n",
      "        [-0.1620],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1617],\n",
      "        [-0.1616],\n",
      "        [-0.1615],\n",
      "        [-0.1617],\n",
      "        [-0.1620],\n",
      "        [-0.1620],\n",
      "        [-0.1621],\n",
      "        [-0.1622],\n",
      "        [-0.1622],\n",
      "        [-0.1621],\n",
      "        [-0.1621],\n",
      "        [-0.1620],\n",
      "        [-0.1620],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1616],\n",
      "        [-0.1616]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1616],\n",
      "        [-0.1617],\n",
      "        [-0.1608],\n",
      "        [-0.1614],\n",
      "        [-0.1620],\n",
      "        [-0.1623],\n",
      "        [-0.1625],\n",
      "        [-0.1627],\n",
      "        [-0.1628],\n",
      "        [-0.1629],\n",
      "        [-0.1629],\n",
      "        [-0.1627],\n",
      "        [-0.1625],\n",
      "        [-0.1623],\n",
      "        [-0.1622],\n",
      "        [-0.1621],\n",
      "        [-0.1620],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1619],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1618],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1617],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1612],\n",
      "        [-0.1612],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1610],\n",
      "        [-0.1611],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1608],\n",
      "        [-0.1607],\n",
      "        [-0.1610],\n",
      "        [-0.1612],\n",
      "        [-0.1613],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1614],\n",
      "        [-0.1613],\n",
      "        [-0.1613],\n",
      "        [-0.1612],\n",
      "        [-0.1612],\n",
      "        [-0.1612],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1609],\n",
      "        [-0.1610],\n",
      "        [-0.1601],\n",
      "        [-0.1608],\n",
      "        [-0.1613],\n",
      "        [-0.1616],\n",
      "        [-0.1618],\n",
      "        [-0.1620],\n",
      "        [-0.1622],\n",
      "        [-0.1622],\n",
      "        [-0.1622],\n",
      "        [-0.1620],\n",
      "        [-0.1618],\n",
      "        [-0.1616],\n",
      "        [-0.1616],\n",
      "        [-0.1614],\n",
      "        [-0.1613],\n",
      "        [-0.1612],\n",
      "        [-0.1612],\n",
      "        [-0.1612],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1611],\n",
      "        [-0.1610],\n",
      "        [-0.1610],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1609],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1606],\n",
      "        [-0.1606],\n",
      "        [-0.1606],\n",
      "        [-0.1606],\n",
      "        [-0.1605],\n",
      "        [-0.1605],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1601],\n",
      "        [-0.1600],\n",
      "        [-0.1603],\n",
      "        [-0.1605],\n",
      "        [-0.1606],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1607],\n",
      "        [-0.1606],\n",
      "        [-0.1606],\n",
      "        [-0.1605],\n",
      "        [-0.1605],\n",
      "        [-0.1605],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1602]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1603],\n",
      "        [-0.1594],\n",
      "        [-0.1600],\n",
      "        [-0.1605],\n",
      "        [-0.1609],\n",
      "        [-0.1611],\n",
      "        [-0.1613],\n",
      "        [-0.1614],\n",
      "        [-0.1615],\n",
      "        [-0.1615],\n",
      "        [-0.1613],\n",
      "        [-0.1610],\n",
      "        [-0.1609],\n",
      "        [-0.1608],\n",
      "        [-0.1607],\n",
      "        [-0.1606],\n",
      "        [-0.1605],\n",
      "        [-0.1605],\n",
      "        [-0.1605],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1604],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1603],\n",
      "        [-0.1602],\n",
      "        [-0.1602],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1601],\n",
      "        [-0.1600],\n",
      "        [-0.1600],\n",
      "        [-0.1600],\n",
      "        [-0.1599],\n",
      "        [-0.1599],\n",
      "        [-0.1599],\n",
      "        [-0.1599],\n",
      "        [-0.1599],\n",
      "        [-0.1599],\n",
      "        [-0.1598],\n",
      "        [-0.1598],\n",
      "        [-0.1598],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1594],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1596],\n",
      "        [-0.1598],\n",
      "        [-0.1599],\n",
      "        [-0.1600],\n",
      "        [-0.1600],\n",
      "        [-0.1600],\n",
      "        [-0.1600],\n",
      "        [-0.1599],\n",
      "        [-0.1598],\n",
      "        [-0.1598],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1593],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1595],\n",
      "        [-0.1586],\n",
      "        [-0.1593],\n",
      "        [-0.1598],\n",
      "        [-0.1601],\n",
      "        [-0.1603],\n",
      "        [-0.1605],\n",
      "        [-0.1607],\n",
      "        [-0.1608],\n",
      "        [-0.1608],\n",
      "        [-0.1605],\n",
      "        [-0.1603],\n",
      "        [-0.1602],\n",
      "        [-0.1601],\n",
      "        [-0.1599],\n",
      "        [-0.1598],\n",
      "        [-0.1598],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1597],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1596],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1593],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1593],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1591],\n",
      "        [-0.1591],\n",
      "        [-0.1591],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1589],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1586],\n",
      "        [-0.1585],\n",
      "        [-0.1588],\n",
      "        [-0.1590],\n",
      "        [-0.1591],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1592],\n",
      "        [-0.1591],\n",
      "        [-0.1591],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1588],\n",
      "        [-0.1579],\n",
      "        [-0.1585],\n",
      "        [-0.1591],\n",
      "        [-0.1594],\n",
      "        [-0.1596],\n",
      "        [-0.1598],\n",
      "        [-0.1600],\n",
      "        [-0.1601],\n",
      "        [-0.1600],\n",
      "        [-0.1598],\n",
      "        [-0.1596],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1592],\n",
      "        [-0.1591],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1589],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1588],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1587],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1584],\n",
      "        [-0.1584],\n",
      "        [-0.1584],\n",
      "        [-0.1584],\n",
      "        [-0.1584],\n",
      "        [-0.1584],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1581],\n",
      "        [-0.1582],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1579],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1579],\n",
      "        [-0.1578],\n",
      "        [-0.1581],\n",
      "        [-0.1583],\n",
      "        [-0.1584],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1585],\n",
      "        [-0.1584],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1580],\n",
      "        [-0.1572],\n",
      "        [-0.1578],\n",
      "        [-0.1583],\n",
      "        [-0.1587],\n",
      "        [-0.1589],\n",
      "        [-0.1591],\n",
      "        [-0.1592],\n",
      "        [-0.1593],\n",
      "        [-0.1593],\n",
      "        [-0.1591],\n",
      "        [-0.1588],\n",
      "        [-0.1587],\n",
      "        [-0.1586],\n",
      "        [-0.1585],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1583],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1582],\n",
      "        [-0.1581],\n",
      "        [-0.1581],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1580],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1578],\n",
      "        [-0.1578],\n",
      "        [-0.1577],\n",
      "        [-0.1577],\n",
      "        [-0.1577],\n",
      "        [-0.1577],\n",
      "        [-0.1577],\n",
      "        [-0.1576],\n",
      "        [-0.1576],\n",
      "        [-0.1576],\n",
      "        [-0.1575],\n",
      "        [-0.1576],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1573],\n",
      "        [-0.1572],\n",
      "        [-0.1571],\n",
      "        [-0.1574],\n",
      "        [-0.1576],\n",
      "        [-0.1577],\n",
      "        [-0.1578],\n",
      "        [-0.1578],\n",
      "        [-0.1578],\n",
      "        [-0.1578],\n",
      "        [-0.1577],\n",
      "        [-0.1576],\n",
      "        [-0.1576],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1572]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1574],\n",
      "        [-0.1565],\n",
      "        [-0.1571],\n",
      "        [-0.1577],\n",
      "        [-0.1580],\n",
      "        [-0.1582],\n",
      "        [-0.1584],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1586],\n",
      "        [-0.1584],\n",
      "        [-0.1581],\n",
      "        [-0.1580],\n",
      "        [-0.1579],\n",
      "        [-0.1578],\n",
      "        [-0.1577],\n",
      "        [-0.1576],\n",
      "        [-0.1576],\n",
      "        [-0.1576],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1575],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.1573],\n",
      "        [-0.1573],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1572],\n",
      "        [-0.1571],\n",
      "        [-0.1571],\n",
      "        [-0.1571],\n",
      "        [-0.1570],\n",
      "        [-0.1570],\n",
      "        [-0.1570],\n",
      "        [-0.1570],\n",
      "        [-0.1570],\n",
      "        [-0.1569],\n",
      "        [-0.1569],\n",
      "        [-0.1568],\n",
      "        [-0.1569],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1566],\n",
      "        [-0.1565],\n",
      "        [-0.1564],\n",
      "        [-0.1567],\n",
      "        [-0.1569],\n",
      "        [-0.1570],\n",
      "        [-0.1571],\n",
      "        [-0.1571],\n",
      "        [-0.1571],\n",
      "        [-0.1571],\n",
      "        [-0.1570],\n",
      "        [-0.1569],\n",
      "        [-0.1569],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1565]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1565],\n",
      "        [-0.1566],\n",
      "        [-0.1557],\n",
      "        [-0.1564],\n",
      "        [-0.1569],\n",
      "        [-0.1572],\n",
      "        [-0.1574],\n",
      "        [-0.1576],\n",
      "        [-0.1578],\n",
      "        [-0.1579],\n",
      "        [-0.1579],\n",
      "        [-0.1576],\n",
      "        [-0.1574],\n",
      "        [-0.1573],\n",
      "        [-0.1572],\n",
      "        [-0.1570],\n",
      "        [-0.1569],\n",
      "        [-0.1569],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1568],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1567],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1566],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1562],\n",
      "        [-0.1562],\n",
      "        [-0.1562],\n",
      "        [-0.1562],\n",
      "        [-0.1561],\n",
      "        [-0.1561],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1557],\n",
      "        [-0.1556],\n",
      "        [-0.1559],\n",
      "        [-0.1561],\n",
      "        [-0.1562],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1563],\n",
      "        [-0.1562],\n",
      "        [-0.1562],\n",
      "        [-0.1561],\n",
      "        [-0.1561],\n",
      "        [-0.1561],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1559],\n",
      "        [-0.1550],\n",
      "        [-0.1556],\n",
      "        [-0.1562],\n",
      "        [-0.1565],\n",
      "        [-0.1567],\n",
      "        [-0.1569],\n",
      "        [-0.1571],\n",
      "        [-0.1572],\n",
      "        [-0.1571],\n",
      "        [-0.1569],\n",
      "        [-0.1567],\n",
      "        [-0.1566],\n",
      "        [-0.1565],\n",
      "        [-0.1563],\n",
      "        [-0.1562],\n",
      "        [-0.1561],\n",
      "        [-0.1561],\n",
      "        [-0.1561],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1560],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1559],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1556],\n",
      "        [-0.1556],\n",
      "        [-0.1556],\n",
      "        [-0.1555],\n",
      "        [-0.1555],\n",
      "        [-0.1555],\n",
      "        [-0.1555],\n",
      "        [-0.1555],\n",
      "        [-0.1555],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1551],\n",
      "        [-0.1550],\n",
      "        [-0.1549],\n",
      "        [-0.1552],\n",
      "        [-0.1554],\n",
      "        [-0.1555],\n",
      "        [-0.1556],\n",
      "        [-0.1556],\n",
      "        [-0.1556],\n",
      "        [-0.1556],\n",
      "        [-0.1555],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1550]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch  40 Train Loss:  0.6879\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1551],\n",
      "        [-0.1542],\n",
      "        [-0.1549],\n",
      "        [-0.1554],\n",
      "        [-0.1558],\n",
      "        [-0.1560],\n",
      "        [-0.1562],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.1562],\n",
      "        [-0.1559],\n",
      "        [-0.1558],\n",
      "        [-0.1557],\n",
      "        [-0.1556],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1552],\n",
      "        [-0.1552],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1551],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1549],\n",
      "        [-0.1549],\n",
      "        [-0.1548],\n",
      "        [-0.1548],\n",
      "        [-0.1548],\n",
      "        [-0.1548],\n",
      "        [-0.1548],\n",
      "        [-0.1547],\n",
      "        [-0.1547],\n",
      "        [-0.1547],\n",
      "        [-0.1546],\n",
      "        [-0.1547],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1544],\n",
      "        [-0.1544],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1544],\n",
      "        [-0.1544],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1542],\n",
      "        [-0.1544],\n",
      "        [-0.1547],\n",
      "        [-0.1548],\n",
      "        [-0.1549],\n",
      "        [-0.1549],\n",
      "        [-0.1549],\n",
      "        [-0.1549],\n",
      "        [-0.1548],\n",
      "        [-0.1547],\n",
      "        [-0.1547],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1542],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1544],\n",
      "        [-0.1535],\n",
      "        [-0.1542],\n",
      "        [-0.1547],\n",
      "        [-0.1551],\n",
      "        [-0.1552],\n",
      "        [-0.1554],\n",
      "        [-0.1556],\n",
      "        [-0.1557],\n",
      "        [-0.1557],\n",
      "        [-0.1554],\n",
      "        [-0.1552],\n",
      "        [-0.1551],\n",
      "        [-0.1550],\n",
      "        [-0.1548],\n",
      "        [-0.1547],\n",
      "        [-0.1547],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1546],\n",
      "        [-0.1545],\n",
      "        [-0.1545],\n",
      "        [-0.1544],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1542],\n",
      "        [-0.1542],\n",
      "        [-0.1543],\n",
      "        [-0.1543],\n",
      "        [-0.1542],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1540],\n",
      "        [-0.1540],\n",
      "        [-0.1540],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1538],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1535],\n",
      "        [-0.1534],\n",
      "        [-0.1537],\n",
      "        [-0.1540],\n",
      "        [-0.1540],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1542],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1540],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1537],\n",
      "        [-0.1528],\n",
      "        [-0.1535],\n",
      "        [-0.1540],\n",
      "        [-0.1544],\n",
      "        [-0.1546],\n",
      "        [-0.1547],\n",
      "        [-0.1549],\n",
      "        [-0.1550],\n",
      "        [-0.1550],\n",
      "        [-0.1548],\n",
      "        [-0.1545],\n",
      "        [-0.1544],\n",
      "        [-0.1543],\n",
      "        [-0.1541],\n",
      "        [-0.1540],\n",
      "        [-0.1540],\n",
      "        [-0.1540],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1539],\n",
      "        [-0.1538],\n",
      "        [-0.1538],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1535],\n",
      "        [-0.1535],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1535],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1533],\n",
      "        [-0.1533],\n",
      "        [-0.1533],\n",
      "        [-0.1532],\n",
      "        [-0.1532],\n",
      "        [-0.1531],\n",
      "        [-0.1532],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1530],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1530],\n",
      "        [-0.1530],\n",
      "        [-0.1530],\n",
      "        [-0.1530],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1530],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1530],\n",
      "        [-0.1528],\n",
      "        [-0.1527],\n",
      "        [-0.1530],\n",
      "        [-0.1533],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1535],\n",
      "        [-0.1535],\n",
      "        [-0.1534],\n",
      "        [-0.1534],\n",
      "        [-0.1533],\n",
      "        [-0.1533],\n",
      "        [-0.1532],\n",
      "        [-0.1532],\n",
      "        [-0.1531],\n",
      "        [-0.1532],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1530],\n",
      "        [-0.1530],\n",
      "        [-0.1529],\n",
      "        [-0.1529]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1530],\n",
      "        [-0.1520],\n",
      "        [-0.1527],\n",
      "        [-0.1533],\n",
      "        [-0.1536],\n",
      "        [-0.1538],\n",
      "        [-0.1540],\n",
      "        [-0.1542],\n",
      "        [-0.1543],\n",
      "        [-0.1542],\n",
      "        [-0.1540],\n",
      "        [-0.1538],\n",
      "        [-0.1536],\n",
      "        [-0.1536],\n",
      "        [-0.1534],\n",
      "        [-0.1533],\n",
      "        [-0.1532],\n",
      "        [-0.1532],\n",
      "        [-0.1532],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1531],\n",
      "        [-0.1530],\n",
      "        [-0.1530],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1529],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1527],\n",
      "        [-0.1527],\n",
      "        [-0.1526],\n",
      "        [-0.1526],\n",
      "        [-0.1526],\n",
      "        [-0.1526],\n",
      "        [-0.1526],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1524],\n",
      "        [-0.1525],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1522],\n",
      "        [-0.1522],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1522],\n",
      "        [-0.1522],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1520],\n",
      "        [-0.1523],\n",
      "        [-0.1525],\n",
      "        [-0.1526],\n",
      "        [-0.1527],\n",
      "        [-0.1527],\n",
      "        [-0.1527],\n",
      "        [-0.1527],\n",
      "        [-0.1526],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1521]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1522],\n",
      "        [-0.1513],\n",
      "        [-0.1520],\n",
      "        [-0.1525],\n",
      "        [-0.1529],\n",
      "        [-0.1531],\n",
      "        [-0.1533],\n",
      "        [-0.1535],\n",
      "        [-0.1535],\n",
      "        [-0.1535],\n",
      "        [-0.1533],\n",
      "        [-0.1530],\n",
      "        [-0.1529],\n",
      "        [-0.1528],\n",
      "        [-0.1527],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1525],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1524],\n",
      "        [-0.1523],\n",
      "        [-0.1523],\n",
      "        [-0.1522],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1520],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1521],\n",
      "        [-0.1520],\n",
      "        [-0.1520],\n",
      "        [-0.1519],\n",
      "        [-0.1519],\n",
      "        [-0.1519],\n",
      "        [-0.1519],\n",
      "        [-0.1519],\n",
      "        [-0.1518],\n",
      "        [-0.1518],\n",
      "        [-0.1518],\n",
      "        [-0.1517],\n",
      "        [-0.1518],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1515],\n",
      "        [-0.1515],\n",
      "        [-0.1515],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1515],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1515],\n",
      "        [-0.1513],\n",
      "        [-0.1512],\n",
      "        [-0.1515],\n",
      "        [-0.1518],\n",
      "        [-0.1519],\n",
      "        [-0.1519],\n",
      "        [-0.1520],\n",
      "        [-0.1520],\n",
      "        [-0.1520],\n",
      "        [-0.1519],\n",
      "        [-0.1518],\n",
      "        [-0.1518],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1516],\n",
      "        [-0.1517],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1515],\n",
      "        [-0.1515],\n",
      "        [-0.1514],\n",
      "        [-0.1514]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1513],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1515],\n",
      "        [-0.1506],\n",
      "        [-0.1513],\n",
      "        [-0.1518],\n",
      "        [-0.1522],\n",
      "        [-0.1524],\n",
      "        [-0.1525],\n",
      "        [-0.1527],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.1525],\n",
      "        [-0.1523],\n",
      "        [-0.1522],\n",
      "        [-0.1521],\n",
      "        [-0.1519],\n",
      "        [-0.1518],\n",
      "        [-0.1518],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1517],\n",
      "        [-0.1516],\n",
      "        [-0.1516],\n",
      "        [-0.1515],\n",
      "        [-0.1515],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1513],\n",
      "        [-0.1513],\n",
      "        [-0.1514],\n",
      "        [-0.1513],\n",
      "        [-0.1513],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1511],\n",
      "        [-0.1511],\n",
      "        [-0.1511],\n",
      "        [-0.1511],\n",
      "        [-0.1510],\n",
      "        [-0.1510],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1508],\n",
      "        [-0.1509],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1506],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1506],\n",
      "        [-0.1505],\n",
      "        [-0.1508],\n",
      "        [-0.1510],\n",
      "        [-0.1511],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1512],\n",
      "        [-0.1511],\n",
      "        [-0.1511],\n",
      "        [-0.1510],\n",
      "        [-0.1510],\n",
      "        [-0.1510],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1507],\n",
      "        [-0.1498],\n",
      "        [-0.1505],\n",
      "        [-0.1511],\n",
      "        [-0.1514],\n",
      "        [-0.1516],\n",
      "        [-0.1518],\n",
      "        [-0.1520],\n",
      "        [-0.1521],\n",
      "        [-0.1520],\n",
      "        [-0.1518],\n",
      "        [-0.1516],\n",
      "        [-0.1514],\n",
      "        [-0.1513],\n",
      "        [-0.1512],\n",
      "        [-0.1511],\n",
      "        [-0.1510],\n",
      "        [-0.1510],\n",
      "        [-0.1510],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1509],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1507],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1505],\n",
      "        [-0.1505],\n",
      "        [-0.1504],\n",
      "        [-0.1504],\n",
      "        [-0.1504],\n",
      "        [-0.1504],\n",
      "        [-0.1504],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1502],\n",
      "        [-0.1503],\n",
      "        [-0.1502],\n",
      "        [-0.1502],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1500],\n",
      "        [-0.1500],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1500],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1497],\n",
      "        [-0.1500],\n",
      "        [-0.1503],\n",
      "        [-0.1504],\n",
      "        [-0.1505],\n",
      "        [-0.1505],\n",
      "        [-0.1505],\n",
      "        [-0.1505],\n",
      "        [-0.1504],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1502],\n",
      "        [-0.1502],\n",
      "        [-0.1501],\n",
      "        [-0.1502],\n",
      "        [-0.1502],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1500],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1499]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1501],\n",
      "        [-0.1491],\n",
      "        [-0.1498],\n",
      "        [-0.1504],\n",
      "        [-0.1507],\n",
      "        [-0.1509],\n",
      "        [-0.1511],\n",
      "        [-0.1513],\n",
      "        [-0.1514],\n",
      "        [-0.1514],\n",
      "        [-0.1511],\n",
      "        [-0.1509],\n",
      "        [-0.1508],\n",
      "        [-0.1507],\n",
      "        [-0.1505],\n",
      "        [-0.1504],\n",
      "        [-0.1504],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1502],\n",
      "        [-0.1502],\n",
      "        [-0.1502],\n",
      "        [-0.1501],\n",
      "        [-0.1501],\n",
      "        [-0.1500],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1498],\n",
      "        [-0.1498],\n",
      "        [-0.1498],\n",
      "        [-0.1497],\n",
      "        [-0.1497],\n",
      "        [-0.1497],\n",
      "        [-0.1497],\n",
      "        [-0.1496],\n",
      "        [-0.1496],\n",
      "        [-0.1496],\n",
      "        [-0.1495],\n",
      "        [-0.1496],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1493],\n",
      "        [-0.1493],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1493],\n",
      "        [-0.1493],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1491],\n",
      "        [-0.1494],\n",
      "        [-0.1496],\n",
      "        [-0.1497],\n",
      "        [-0.1498],\n",
      "        [-0.1498],\n",
      "        [-0.1498],\n",
      "        [-0.1498],\n",
      "        [-0.1497],\n",
      "        [-0.1496],\n",
      "        [-0.1496],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1492]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1491],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1493],\n",
      "        [-0.1483],\n",
      "        [-0.1491],\n",
      "        [-0.1496],\n",
      "        [-0.1500],\n",
      "        [-0.1502],\n",
      "        [-0.1504],\n",
      "        [-0.1505],\n",
      "        [-0.1506],\n",
      "        [-0.1506],\n",
      "        [-0.1504],\n",
      "        [-0.1501],\n",
      "        [-0.1500],\n",
      "        [-0.1499],\n",
      "        [-0.1497],\n",
      "        [-0.1496],\n",
      "        [-0.1496],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1495],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.1493],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1491],\n",
      "        [-0.1491],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1491],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1489],\n",
      "        [-0.1489],\n",
      "        [-0.1489],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1486],\n",
      "        [-0.1487],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1484],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1484],\n",
      "        [-0.1483],\n",
      "        [-0.1486],\n",
      "        [-0.1489],\n",
      "        [-0.1489],\n",
      "        [-0.1490],\n",
      "        [-0.1490],\n",
      "        [-0.1491],\n",
      "        [-0.1490],\n",
      "        [-0.1489],\n",
      "        [-0.1489],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1486],\n",
      "        [-0.1476],\n",
      "        [-0.1483],\n",
      "        [-0.1489],\n",
      "        [-0.1493],\n",
      "        [-0.1495],\n",
      "        [-0.1496],\n",
      "        [-0.1498],\n",
      "        [-0.1499],\n",
      "        [-0.1499],\n",
      "        [-0.1496],\n",
      "        [-0.1494],\n",
      "        [-0.1493],\n",
      "        [-0.1492],\n",
      "        [-0.1490],\n",
      "        [-0.1489],\n",
      "        [-0.1489],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1488],\n",
      "        [-0.1487],\n",
      "        [-0.1487],\n",
      "        [-0.1486],\n",
      "        [-0.1486],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1485],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1482],\n",
      "        [-0.1482],\n",
      "        [-0.1482],\n",
      "        [-0.1482],\n",
      "        [-0.1481],\n",
      "        [-0.1481],\n",
      "        [-0.1480],\n",
      "        [-0.1481],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1478],\n",
      "        [-0.1477],\n",
      "        [-0.1476],\n",
      "        [-0.1479],\n",
      "        [-0.1481],\n",
      "        [-0.1482],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.1482],\n",
      "        [-0.1481],\n",
      "        [-0.1481],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1477]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1478],\n",
      "        [-0.1469],\n",
      "        [-0.1476],\n",
      "        [-0.1482],\n",
      "        [-0.1485],\n",
      "        [-0.1487],\n",
      "        [-0.1489],\n",
      "        [-0.1491],\n",
      "        [-0.1492],\n",
      "        [-0.1492],\n",
      "        [-0.1489],\n",
      "        [-0.1487],\n",
      "        [-0.1486],\n",
      "        [-0.1485],\n",
      "        [-0.1483],\n",
      "        [-0.1482],\n",
      "        [-0.1481],\n",
      "        [-0.1481],\n",
      "        [-0.1481],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1480],\n",
      "        [-0.1479],\n",
      "        [-0.1479],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1478],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1476],\n",
      "        [-0.1476],\n",
      "        [-0.1475],\n",
      "        [-0.1475],\n",
      "        [-0.1475],\n",
      "        [-0.1475],\n",
      "        [-0.1475],\n",
      "        [-0.1474],\n",
      "        [-0.1474],\n",
      "        [-0.1474],\n",
      "        [-0.1473],\n",
      "        [-0.1474],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1471],\n",
      "        [-0.1471],\n",
      "        [-0.1471],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1471],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1471],\n",
      "        [-0.1469],\n",
      "        [-0.1468],\n",
      "        [-0.1471],\n",
      "        [-0.1474],\n",
      "        [-0.1475],\n",
      "        [-0.1476],\n",
      "        [-0.1476],\n",
      "        [-0.1476],\n",
      "        [-0.1476],\n",
      "        [-0.1475],\n",
      "        [-0.1474],\n",
      "        [-0.1474],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1472],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1472],\n",
      "        [-0.1471],\n",
      "        [-0.1471],\n",
      "        [-0.1470],\n",
      "        [-0.1470]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1471],\n",
      "        [-0.1461],\n",
      "        [-0.1468],\n",
      "        [-0.1474],\n",
      "        [-0.1478],\n",
      "        [-0.1480],\n",
      "        [-0.1481],\n",
      "        [-0.1483],\n",
      "        [-0.1484],\n",
      "        [-0.1484],\n",
      "        [-0.1482],\n",
      "        [-0.1479],\n",
      "        [-0.1478],\n",
      "        [-0.1477],\n",
      "        [-0.1475],\n",
      "        [-0.1474],\n",
      "        [-0.1474],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1473],\n",
      "        [-0.1472],\n",
      "        [-0.1471],\n",
      "        [-0.1471],\n",
      "        [-0.1471],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1469],\n",
      "        [-0.1468],\n",
      "        [-0.1468],\n",
      "        [-0.1468],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1466],\n",
      "        [-0.1465],\n",
      "        [-0.1466],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1463],\n",
      "        [-0.1462],\n",
      "        [-0.1461],\n",
      "        [-0.1464],\n",
      "        [-0.1466],\n",
      "        [-0.1467],\n",
      "        [-0.1468],\n",
      "        [-0.1468],\n",
      "        [-0.1468],\n",
      "        [-0.1468],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1466],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1462]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1464],\n",
      "        [-0.1454],\n",
      "        [-0.1461],\n",
      "        [-0.1467],\n",
      "        [-0.1471],\n",
      "        [-0.1473],\n",
      "        [-0.1474],\n",
      "        [-0.1476],\n",
      "        [-0.1477],\n",
      "        [-0.1477],\n",
      "        [-0.1474],\n",
      "        [-0.1472],\n",
      "        [-0.1471],\n",
      "        [-0.1470],\n",
      "        [-0.1468],\n",
      "        [-0.1467],\n",
      "        [-0.1467],\n",
      "        [-0.1466],\n",
      "        [-0.1466],\n",
      "        [-0.1466],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1465],\n",
      "        [-0.1464],\n",
      "        [-0.1464],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1463],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1462],\n",
      "        [-0.1461],\n",
      "        [-0.1461],\n",
      "        [-0.1461],\n",
      "        [-0.1460],\n",
      "        [-0.1460],\n",
      "        [-0.1460],\n",
      "        [-0.1460],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1458],\n",
      "        [-0.1459],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1456],\n",
      "        [-0.1456],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1456],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1453],\n",
      "        [-0.1457],\n",
      "        [-0.1459],\n",
      "        [-0.1460],\n",
      "        [-0.1461],\n",
      "        [-0.1461],\n",
      "        [-0.1461],\n",
      "        [-0.1461],\n",
      "        [-0.1460],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1455]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1454],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1456],\n",
      "        [-0.1446],\n",
      "        [-0.1454],\n",
      "        [-0.1460],\n",
      "        [-0.1463],\n",
      "        [-0.1465],\n",
      "        [-0.1467],\n",
      "        [-0.1469],\n",
      "        [-0.1470],\n",
      "        [-0.1470],\n",
      "        [-0.1467],\n",
      "        [-0.1465],\n",
      "        [-0.1464],\n",
      "        [-0.1463],\n",
      "        [-0.1461],\n",
      "        [-0.1460],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1458],\n",
      "        [-0.1457],\n",
      "        [-0.1457],\n",
      "        [-0.1456],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1454],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1454],\n",
      "        [-0.1453],\n",
      "        [-0.1453],\n",
      "        [-0.1453],\n",
      "        [-0.1453],\n",
      "        [-0.1453],\n",
      "        [-0.1453],\n",
      "        [-0.1452],\n",
      "        [-0.1452],\n",
      "        [-0.1452],\n",
      "        [-0.1451],\n",
      "        [-0.1451],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1449],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1449],\n",
      "        [-0.1449],\n",
      "        [-0.1449],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1447],\n",
      "        [-0.1446],\n",
      "        [-0.1449],\n",
      "        [-0.1452],\n",
      "        [-0.1453],\n",
      "        [-0.1454],\n",
      "        [-0.1454],\n",
      "        [-0.1454],\n",
      "        [-0.1454],\n",
      "        [-0.1453],\n",
      "        [-0.1452],\n",
      "        [-0.1451],\n",
      "        [-0.1451],\n",
      "        [-0.1451],\n",
      "        [-0.1450],\n",
      "        [-0.1451],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1447],\n",
      "        [-0.1447],\n",
      "        [-0.1448],\n",
      "        [-0.1449],\n",
      "        [-0.1439],\n",
      "        [-0.1446],\n",
      "        [-0.1453],\n",
      "        [-0.1456],\n",
      "        [-0.1458],\n",
      "        [-0.1460],\n",
      "        [-0.1462],\n",
      "        [-0.1463],\n",
      "        [-0.1462],\n",
      "        [-0.1460],\n",
      "        [-0.1457],\n",
      "        [-0.1456],\n",
      "        [-0.1455],\n",
      "        [-0.1453],\n",
      "        [-0.1452],\n",
      "        [-0.1452],\n",
      "        [-0.1452],\n",
      "        [-0.1452],\n",
      "        [-0.1451],\n",
      "        [-0.1451],\n",
      "        [-0.1451],\n",
      "        [-0.1450],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1449],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1447],\n",
      "        [-0.1447],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1447],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1445],\n",
      "        [-0.1445],\n",
      "        [-0.1445],\n",
      "        [-0.1444],\n",
      "        [-0.1444],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1442],\n",
      "        [-0.1443],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1439],\n",
      "        [-0.1442],\n",
      "        [-0.1445],\n",
      "        [-0.1446],\n",
      "        [-0.1446],\n",
      "        [-0.1447],\n",
      "        [-0.1447],\n",
      "        [-0.1446],\n",
      "        [-0.1445],\n",
      "        [-0.1445],\n",
      "        [-0.1444],\n",
      "        [-0.1444],\n",
      "        [-0.1444],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1441]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1439],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1441],\n",
      "        [-0.1431],\n",
      "        [-0.1439],\n",
      "        [-0.1445],\n",
      "        [-0.1449],\n",
      "        [-0.1450],\n",
      "        [-0.1452],\n",
      "        [-0.1454],\n",
      "        [-0.1455],\n",
      "        [-0.1455],\n",
      "        [-0.1452],\n",
      "        [-0.1450],\n",
      "        [-0.1449],\n",
      "        [-0.1448],\n",
      "        [-0.1446],\n",
      "        [-0.1445],\n",
      "        [-0.1444],\n",
      "        [-0.1444],\n",
      "        [-0.1444],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1443],\n",
      "        [-0.1442],\n",
      "        [-0.1442],\n",
      "        [-0.1441],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1439],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1440],\n",
      "        [-0.1439],\n",
      "        [-0.1438],\n",
      "        [-0.1438],\n",
      "        [-0.1438],\n",
      "        [-0.1438],\n",
      "        [-0.1438],\n",
      "        [-0.1438],\n",
      "        [-0.1437],\n",
      "        [-0.1437],\n",
      "        [-0.1437],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1435],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1432],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1432],\n",
      "        [-0.1431],\n",
      "        [-0.1434],\n",
      "        [-0.1437],\n",
      "        [-0.1438],\n",
      "        [-0.1439],\n",
      "        [-0.1439],\n",
      "        [-0.1439],\n",
      "        [-0.1439],\n",
      "        [-0.1438],\n",
      "        [-0.1437],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1432],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1434],\n",
      "        [-0.1424],\n",
      "        [-0.1431],\n",
      "        [-0.1438],\n",
      "        [-0.1441],\n",
      "        [-0.1443],\n",
      "        [-0.1445],\n",
      "        [-0.1447],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.1445],\n",
      "        [-0.1443],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1439],\n",
      "        [-0.1437],\n",
      "        [-0.1437],\n",
      "        [-0.1437],\n",
      "        [-0.1437],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1435],\n",
      "        [-0.1435],\n",
      "        [-0.1434],\n",
      "        [-0.1434],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1432],\n",
      "        [-0.1432],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1432],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1430],\n",
      "        [-0.1430],\n",
      "        [-0.1430],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1427],\n",
      "        [-0.1428],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1425],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1425],\n",
      "        [-0.1424],\n",
      "        [-0.1427],\n",
      "        [-0.1430],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1432],\n",
      "        [-0.1432],\n",
      "        [-0.1431],\n",
      "        [-0.1431],\n",
      "        [-0.1430],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1426]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1427],\n",
      "        [-0.1417],\n",
      "        [-0.1424],\n",
      "        [-0.1431],\n",
      "        [-0.1434],\n",
      "        [-0.1436],\n",
      "        [-0.1438],\n",
      "        [-0.1440],\n",
      "        [-0.1441],\n",
      "        [-0.1440],\n",
      "        [-0.1438],\n",
      "        [-0.1435],\n",
      "        [-0.1434],\n",
      "        [-0.1433],\n",
      "        [-0.1431],\n",
      "        [-0.1430],\n",
      "        [-0.1430],\n",
      "        [-0.1430],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1428],\n",
      "        [-0.1428],\n",
      "        [-0.1427],\n",
      "        [-0.1427],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1426],\n",
      "        [-0.1425],\n",
      "        [-0.1425],\n",
      "        [-0.1424],\n",
      "        [-0.1424],\n",
      "        [-0.1424],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1422],\n",
      "        [-0.1421],\n",
      "        [-0.1422],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1419],\n",
      "        [-0.1418],\n",
      "        [-0.1417],\n",
      "        [-0.1420],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1424],\n",
      "        [-0.1424],\n",
      "        [-0.1424],\n",
      "        [-0.1424],\n",
      "        [-0.1423],\n",
      "        [-0.1423],\n",
      "        [-0.1422],\n",
      "        [-0.1421],\n",
      "        [-0.1422],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1418]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jh/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100, 2])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1417],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1419],\n",
      "        [-0.1409],\n",
      "        [-0.1417],\n",
      "        [-0.1423],\n",
      "        [-0.1427],\n",
      "        [-0.1429],\n",
      "        [-0.1430],\n",
      "        [-0.1432],\n",
      "        [-0.1433],\n",
      "        [-0.1433],\n",
      "        [-0.1430],\n",
      "        [-0.1428],\n",
      "        [-0.1427],\n",
      "        [-0.1426],\n",
      "        [-0.1424],\n",
      "        [-0.1423],\n",
      "        [-0.1422],\n",
      "        [-0.1422],\n",
      "        [-0.1422],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1421],\n",
      "        [-0.1420],\n",
      "        [-0.1420],\n",
      "        [-0.1419],\n",
      "        [-0.1419],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1417],\n",
      "        [-0.1417],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1417],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1415],\n",
      "        [-0.1415],\n",
      "        [-0.1415],\n",
      "        [-0.1414],\n",
      "        [-0.1414],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1412],\n",
      "        [-0.1413],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1410],\n",
      "        [-0.1410],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1410],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1410],\n",
      "        [-0.1409],\n",
      "        [-0.1412],\n",
      "        [-0.1415],\n",
      "        [-0.1416],\n",
      "        [-0.1417],\n",
      "        [-0.1417],\n",
      "        [-0.1417],\n",
      "        [-0.1416],\n",
      "        [-0.1416],\n",
      "        [-0.1415],\n",
      "        [-0.1414],\n",
      "        [-0.1414],\n",
      "        [-0.1414],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1411]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1410],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1412],\n",
      "        [-0.1402],\n",
      "        [-0.1409],\n",
      "        [-0.1416],\n",
      "        [-0.1420],\n",
      "        [-0.1422],\n",
      "        [-0.1423],\n",
      "        [-0.1425],\n",
      "        [-0.1426],\n",
      "        [-0.1426],\n",
      "        [-0.1423],\n",
      "        [-0.1421],\n",
      "        [-0.1420],\n",
      "        [-0.1419],\n",
      "        [-0.1417],\n",
      "        [-0.1416],\n",
      "        [-0.1415],\n",
      "        [-0.1415],\n",
      "        [-0.1415],\n",
      "        [-0.1414],\n",
      "        [-0.1414],\n",
      "        [-0.1414],\n",
      "        [-0.1413],\n",
      "        [-0.1413],\n",
      "        [-0.1412],\n",
      "        [-0.1412],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1410],\n",
      "        [-0.1410],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1410],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1408],\n",
      "        [-0.1408],\n",
      "        [-0.1408],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1405],\n",
      "        [-0.1406],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1403],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1403],\n",
      "        [-0.1402],\n",
      "        [-0.1405],\n",
      "        [-0.1408],\n",
      "        [-0.1409],\n",
      "        [-0.1410],\n",
      "        [-0.1410],\n",
      "        [-0.1410],\n",
      "        [-0.1409],\n",
      "        [-0.1409],\n",
      "        [-0.1408],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1404]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch  60 Train Loss:  0.6680\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1405],\n",
      "        [-0.1394],\n",
      "        [-0.1402],\n",
      "        [-0.1408],\n",
      "        [-0.1412],\n",
      "        [-0.1414],\n",
      "        [-0.1416],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1418],\n",
      "        [-0.1416],\n",
      "        [-0.1413],\n",
      "        [-0.1412],\n",
      "        [-0.1411],\n",
      "        [-0.1409],\n",
      "        [-0.1408],\n",
      "        [-0.1408],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1407],\n",
      "        [-0.1406],\n",
      "        [-0.1406],\n",
      "        [-0.1405],\n",
      "        [-0.1405],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1403],\n",
      "        [-0.1402],\n",
      "        [-0.1402],\n",
      "        [-0.1402],\n",
      "        [-0.1401],\n",
      "        [-0.1401],\n",
      "        [-0.1401],\n",
      "        [-0.1401],\n",
      "        [-0.1400],\n",
      "        [-0.1400],\n",
      "        [-0.1400],\n",
      "        [-0.1399],\n",
      "        [-0.1400],\n",
      "        [-0.1399],\n",
      "        [-0.1399],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1397],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1397],\n",
      "        [-0.1397],\n",
      "        [-0.1397],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1397],\n",
      "        [-0.1395],\n",
      "        [-0.1394],\n",
      "        [-0.1397],\n",
      "        [-0.1400],\n",
      "        [-0.1401],\n",
      "        [-0.1402],\n",
      "        [-0.1402],\n",
      "        [-0.1402],\n",
      "        [-0.1402],\n",
      "        [-0.1401],\n",
      "        [-0.1400],\n",
      "        [-0.1400],\n",
      "        [-0.1399],\n",
      "        [-0.1399],\n",
      "        [-0.1398],\n",
      "        [-0.1399],\n",
      "        [-0.1399],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1397],\n",
      "        [-0.1397],\n",
      "        [-0.1396],\n",
      "        [-0.1396]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1395],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1397],\n",
      "        [-0.1386],\n",
      "        [-0.1394],\n",
      "        [-0.1401],\n",
      "        [-0.1405],\n",
      "        [-0.1407],\n",
      "        [-0.1408],\n",
      "        [-0.1410],\n",
      "        [-0.1411],\n",
      "        [-0.1411],\n",
      "        [-0.1408],\n",
      "        [-0.1406],\n",
      "        [-0.1405],\n",
      "        [-0.1404],\n",
      "        [-0.1402],\n",
      "        [-0.1401],\n",
      "        [-0.1400],\n",
      "        [-0.1400],\n",
      "        [-0.1400],\n",
      "        [-0.1399],\n",
      "        [-0.1399],\n",
      "        [-0.1399],\n",
      "        [-0.1398],\n",
      "        [-0.1398],\n",
      "        [-0.1397],\n",
      "        [-0.1397],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1395],\n",
      "        [-0.1395],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1395],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1393],\n",
      "        [-0.1393],\n",
      "        [-0.1393],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1390],\n",
      "        [-0.1391],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1389],\n",
      "        [-0.1388],\n",
      "        [-0.1387],\n",
      "        [-0.1390],\n",
      "        [-0.1393],\n",
      "        [-0.1394],\n",
      "        [-0.1395],\n",
      "        [-0.1395],\n",
      "        [-0.1395],\n",
      "        [-0.1394],\n",
      "        [-0.1394],\n",
      "        [-0.1393],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1390],\n",
      "        [-0.1379],\n",
      "        [-0.1387],\n",
      "        [-0.1394],\n",
      "        [-0.1398],\n",
      "        [-0.1399],\n",
      "        [-0.1401],\n",
      "        [-0.1403],\n",
      "        [-0.1404],\n",
      "        [-0.1404],\n",
      "        [-0.1401],\n",
      "        [-0.1399],\n",
      "        [-0.1397],\n",
      "        [-0.1396],\n",
      "        [-0.1395],\n",
      "        [-0.1393],\n",
      "        [-0.1393],\n",
      "        [-0.1393],\n",
      "        [-0.1393],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1391],\n",
      "        [-0.1391],\n",
      "        [-0.1390],\n",
      "        [-0.1390],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1389],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1387],\n",
      "        [-0.1387],\n",
      "        [-0.1387],\n",
      "        [-0.1387],\n",
      "        [-0.1386],\n",
      "        [-0.1386],\n",
      "        [-0.1386],\n",
      "        [-0.1386],\n",
      "        [-0.1385],\n",
      "        [-0.1384],\n",
      "        [-0.1385],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1382],\n",
      "        [-0.1381],\n",
      "        [-0.1379],\n",
      "        [-0.1383],\n",
      "        [-0.1386],\n",
      "        [-0.1386],\n",
      "        [-0.1387],\n",
      "        [-0.1387],\n",
      "        [-0.1388],\n",
      "        [-0.1387],\n",
      "        [-0.1386],\n",
      "        [-0.1386],\n",
      "        [-0.1385],\n",
      "        [-0.1384],\n",
      "        [-0.1385],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1381]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1380],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1382],\n",
      "        [-0.1371],\n",
      "        [-0.1379],\n",
      "        [-0.1386],\n",
      "        [-0.1390],\n",
      "        [-0.1392],\n",
      "        [-0.1393],\n",
      "        [-0.1395],\n",
      "        [-0.1396],\n",
      "        [-0.1396],\n",
      "        [-0.1393],\n",
      "        [-0.1391],\n",
      "        [-0.1390],\n",
      "        [-0.1389],\n",
      "        [-0.1387],\n",
      "        [-0.1386],\n",
      "        [-0.1385],\n",
      "        [-0.1385],\n",
      "        [-0.1385],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1384],\n",
      "        [-0.1383],\n",
      "        [-0.1383],\n",
      "        [-0.1382],\n",
      "        [-0.1382],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1380],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1378],\n",
      "        [-0.1378],\n",
      "        [-0.1378],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1375],\n",
      "        [-0.1376],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1374],\n",
      "        [-0.1373],\n",
      "        [-0.1372],\n",
      "        [-0.1375],\n",
      "        [-0.1378],\n",
      "        [-0.1379],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.1379],\n",
      "        [-0.1379],\n",
      "        [-0.1378],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1374]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1375],\n",
      "        [-0.1364],\n",
      "        [-0.1372],\n",
      "        [-0.1379],\n",
      "        [-0.1383],\n",
      "        [-0.1385],\n",
      "        [-0.1386],\n",
      "        [-0.1388],\n",
      "        [-0.1389],\n",
      "        [-0.1389],\n",
      "        [-0.1386],\n",
      "        [-0.1384],\n",
      "        [-0.1383],\n",
      "        [-0.1382],\n",
      "        [-0.1380],\n",
      "        [-0.1378],\n",
      "        [-0.1378],\n",
      "        [-0.1378],\n",
      "        [-0.1378],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [-0.1376],\n",
      "        [-0.1376],\n",
      "        [-0.1375],\n",
      "        [-0.1375],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1374],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1374],\n",
      "        [-0.1373],\n",
      "        [-0.1373],\n",
      "        [-0.1372],\n",
      "        [-0.1372],\n",
      "        [-0.1372],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1370],\n",
      "        [-0.1369],\n",
      "        [-0.1370],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1367],\n",
      "        [-0.1367],\n",
      "        [-0.1367],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1367],\n",
      "        [-0.1367],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1367],\n",
      "        [-0.1366],\n",
      "        [-0.1364],\n",
      "        [-0.1368],\n",
      "        [-0.1371],\n",
      "        [-0.1372],\n",
      "        [-0.1372],\n",
      "        [-0.1372],\n",
      "        [-0.1373],\n",
      "        [-0.1372],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1370],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1367],\n",
      "        [-0.1366],\n",
      "        [-0.1366]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1365],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1367],\n",
      "        [-0.1356],\n",
      "        [-0.1364],\n",
      "        [-0.1371],\n",
      "        [-0.1375],\n",
      "        [-0.1377],\n",
      "        [-0.1379],\n",
      "        [-0.1380],\n",
      "        [-0.1381],\n",
      "        [-0.1381],\n",
      "        [-0.1379],\n",
      "        [-0.1376],\n",
      "        [-0.1375],\n",
      "        [-0.1374],\n",
      "        [-0.1372],\n",
      "        [-0.1371],\n",
      "        [-0.1371],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.1369],\n",
      "        [-0.1369],\n",
      "        [-0.1368],\n",
      "        [-0.1368],\n",
      "        [-0.1367],\n",
      "        [-0.1367],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1365],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1366],\n",
      "        [-0.1365],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1363],\n",
      "        [-0.1363],\n",
      "        [-0.1363],\n",
      "        [-0.1362],\n",
      "        [-0.1362],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1360],\n",
      "        [-0.1361],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1359],\n",
      "        [-0.1358],\n",
      "        [-0.1357],\n",
      "        [-0.1360],\n",
      "        [-0.1363],\n",
      "        [-0.1364],\n",
      "        [-0.1365],\n",
      "        [-0.1365],\n",
      "        [-0.1365],\n",
      "        [-0.1365],\n",
      "        [-0.1364],\n",
      "        [-0.1363],\n",
      "        [-0.1362],\n",
      "        [-0.1362],\n",
      "        [-0.1362],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1359]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1358],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1360],\n",
      "        [-0.1349],\n",
      "        [-0.1358],\n",
      "        [-0.1364],\n",
      "        [-0.1368],\n",
      "        [-0.1370],\n",
      "        [-0.1372],\n",
      "        [-0.1374],\n",
      "        [-0.1375],\n",
      "        [-0.1374],\n",
      "        [-0.1372],\n",
      "        [-0.1369],\n",
      "        [-0.1368],\n",
      "        [-0.1367],\n",
      "        [-0.1365],\n",
      "        [-0.1364],\n",
      "        [-0.1364],\n",
      "        [-0.1363],\n",
      "        [-0.1363],\n",
      "        [-0.1363],\n",
      "        [-0.1362],\n",
      "        [-0.1362],\n",
      "        [-0.1362],\n",
      "        [-0.1361],\n",
      "        [-0.1361],\n",
      "        [-0.1360],\n",
      "        [-0.1360],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1358],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1357],\n",
      "        [-0.1357],\n",
      "        [-0.1357],\n",
      "        [-0.1357],\n",
      "        [-0.1357],\n",
      "        [-0.1356],\n",
      "        [-0.1356],\n",
      "        [-0.1356],\n",
      "        [-0.1355],\n",
      "        [-0.1355],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1353],\n",
      "        [-0.1354],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1352],\n",
      "        [-0.1351],\n",
      "        [-0.1350],\n",
      "        [-0.1353],\n",
      "        [-0.1356],\n",
      "        [-0.1357],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1358],\n",
      "        [-0.1357],\n",
      "        [-0.1356],\n",
      "        [-0.1355],\n",
      "        [-0.1355],\n",
      "        [-0.1355],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1352]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1353],\n",
      "        [-0.1341],\n",
      "        [-0.1350],\n",
      "        [-0.1357],\n",
      "        [-0.1361],\n",
      "        [-0.1363],\n",
      "        [-0.1364],\n",
      "        [-0.1366],\n",
      "        [-0.1367],\n",
      "        [-0.1367],\n",
      "        [-0.1364],\n",
      "        [-0.1362],\n",
      "        [-0.1360],\n",
      "        [-0.1359],\n",
      "        [-0.1357],\n",
      "        [-0.1356],\n",
      "        [-0.1356],\n",
      "        [-0.1356],\n",
      "        [-0.1356],\n",
      "        [-0.1355],\n",
      "        [-0.1355],\n",
      "        [-0.1355],\n",
      "        [-0.1354],\n",
      "        [-0.1354],\n",
      "        [-0.1353],\n",
      "        [-0.1353],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1349],\n",
      "        [-0.1349],\n",
      "        [-0.1349],\n",
      "        [-0.1348],\n",
      "        [-0.1348],\n",
      "        [-0.1348],\n",
      "        [-0.1347],\n",
      "        [-0.1348],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1345],\n",
      "        [-0.1345],\n",
      "        [-0.1345],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1345],\n",
      "        [-0.1343],\n",
      "        [-0.1342],\n",
      "        [-0.1346],\n",
      "        [-0.1348],\n",
      "        [-0.1349],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1350],\n",
      "        [-0.1349],\n",
      "        [-0.1348],\n",
      "        [-0.1348],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1345],\n",
      "        [-0.1345],\n",
      "        [-0.1344],\n",
      "        [-0.1344]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1343],\n",
      "        [-0.1343],\n",
      "        [-0.1343],\n",
      "        [-0.1345],\n",
      "        [-0.1334],\n",
      "        [-0.1342],\n",
      "        [-0.1349],\n",
      "        [-0.1353],\n",
      "        [-0.1355],\n",
      "        [-0.1356],\n",
      "        [-0.1358],\n",
      "        [-0.1359],\n",
      "        [-0.1359],\n",
      "        [-0.1356],\n",
      "        [-0.1354],\n",
      "        [-0.1353],\n",
      "        [-0.1352],\n",
      "        [-0.1350],\n",
      "        [-0.1349],\n",
      "        [-0.1348],\n",
      "        [-0.1348],\n",
      "        [-0.1348],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1347],\n",
      "        [-0.1346],\n",
      "        [-0.1346],\n",
      "        [-0.1345],\n",
      "        [-0.1345],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1343],\n",
      "        [-0.1343],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1343],\n",
      "        [-0.1342],\n",
      "        [-0.1342],\n",
      "        [-0.1342],\n",
      "        [-0.1342],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1340],\n",
      "        [-0.1339],\n",
      "        [-0.1340],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1337],\n",
      "        [-0.1337],\n",
      "        [-0.1337],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1337],\n",
      "        [-0.1337],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1337],\n",
      "        [-0.1335],\n",
      "        [-0.1334],\n",
      "        [-0.1338],\n",
      "        [-0.1341],\n",
      "        [-0.1342],\n",
      "        [-0.1342],\n",
      "        [-0.1343],\n",
      "        [-0.1343],\n",
      "        [-0.1342],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1340],\n",
      "        [-0.1339],\n",
      "        [-0.1340],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1337],\n",
      "        [-0.1336],\n",
      "        [-0.1336]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1338],\n",
      "        [-0.1326],\n",
      "        [-0.1335],\n",
      "        [-0.1342],\n",
      "        [-0.1346],\n",
      "        [-0.1348],\n",
      "        [-0.1349],\n",
      "        [-0.1351],\n",
      "        [-0.1352],\n",
      "        [-0.1352],\n",
      "        [-0.1349],\n",
      "        [-0.1347],\n",
      "        [-0.1345],\n",
      "        [-0.1344],\n",
      "        [-0.1342],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1341],\n",
      "        [-0.1340],\n",
      "        [-0.1340],\n",
      "        [-0.1340],\n",
      "        [-0.1339],\n",
      "        [-0.1339],\n",
      "        [-0.1338],\n",
      "        [-0.1338],\n",
      "        [-0.1337],\n",
      "        [-0.1337],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1336],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1334],\n",
      "        [-0.1334],\n",
      "        [-0.1334],\n",
      "        [-0.1333],\n",
      "        [-0.1333],\n",
      "        [-0.1333],\n",
      "        [-0.1332],\n",
      "        [-0.1333],\n",
      "        [-0.1331],\n",
      "        [-0.1332],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1331],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1328],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1330],\n",
      "        [-0.1328],\n",
      "        [-0.1327],\n",
      "        [-0.1330],\n",
      "        [-0.1333],\n",
      "        [-0.1334],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1335],\n",
      "        [-0.1334],\n",
      "        [-0.1333],\n",
      "        [-0.1333],\n",
      "        [-0.1332],\n",
      "        [-0.1332],\n",
      "        [-0.1331],\n",
      "        [-0.1332],\n",
      "        [-0.1332],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1329],\n",
      "        [-0.1329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1328],\n",
      "        [-0.1328],\n",
      "        [-0.1328],\n",
      "        [-0.1330],\n",
      "        [-0.1318],\n",
      "        [-0.1327],\n",
      "        [-0.1334],\n",
      "        [-0.1338],\n",
      "        [-0.1340],\n",
      "        [-0.1341],\n",
      "        [-0.1343],\n",
      "        [-0.1344],\n",
      "        [-0.1344],\n",
      "        [-0.1341],\n",
      "        [-0.1339],\n",
      "        [-0.1338],\n",
      "        [-0.1337],\n",
      "        [-0.1335],\n",
      "        [-0.1334],\n",
      "        [-0.1333],\n",
      "        [-0.1333],\n",
      "        [-0.1333],\n",
      "        [-0.1332],\n",
      "        [-0.1332],\n",
      "        [-0.1332],\n",
      "        [-0.1331],\n",
      "        [-0.1331],\n",
      "        [-0.1330],\n",
      "        [-0.1330],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1329],\n",
      "        [-0.1328],\n",
      "        [-0.1328],\n",
      "        [-0.1328],\n",
      "        [-0.1329],\n",
      "        [-0.1328],\n",
      "        [-0.1328],\n",
      "        [-0.1327],\n",
      "        [-0.1327],\n",
      "        [-0.1327],\n",
      "        [-0.1326],\n",
      "        [-0.1326],\n",
      "        [-0.1326],\n",
      "        [-0.1325],\n",
      "        [-0.1325],\n",
      "        [-0.1325],\n",
      "        [-0.1324],\n",
      "        [-0.1325],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1322],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1322],\n",
      "        [-0.1320],\n",
      "        [-0.1319],\n",
      "        [-0.1323],\n",
      "        [-0.1326],\n",
      "        [-0.1327],\n",
      "        [-0.1327],\n",
      "        [-0.1327],\n",
      "        [-0.1328],\n",
      "        [-0.1327],\n",
      "        [-0.1326],\n",
      "        [-0.1325],\n",
      "        [-0.1325],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1322],\n",
      "        [-0.1321],\n",
      "        [-0.1321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1323],\n",
      "        [-0.1311],\n",
      "        [-0.1320],\n",
      "        [-0.1327],\n",
      "        [-0.1331],\n",
      "        [-0.1333],\n",
      "        [-0.1334],\n",
      "        [-0.1336],\n",
      "        [-0.1337],\n",
      "        [-0.1337],\n",
      "        [-0.1334],\n",
      "        [-0.1332],\n",
      "        [-0.1331],\n",
      "        [-0.1329],\n",
      "        [-0.1328],\n",
      "        [-0.1326],\n",
      "        [-0.1326],\n",
      "        [-0.1326],\n",
      "        [-0.1326],\n",
      "        [-0.1325],\n",
      "        [-0.1325],\n",
      "        [-0.1325],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.1323],\n",
      "        [-0.1323],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1321],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1319],\n",
      "        [-0.1319],\n",
      "        [-0.1319],\n",
      "        [-0.1318],\n",
      "        [-0.1318],\n",
      "        [-0.1318],\n",
      "        [-0.1317],\n",
      "        [-0.1318],\n",
      "        [-0.1317],\n",
      "        [-0.1317],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1315],\n",
      "        [-0.1315],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1315],\n",
      "        [-0.1315],\n",
      "        [-0.1315],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1313],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1315],\n",
      "        [-0.1313],\n",
      "        [-0.1312],\n",
      "        [-0.1316],\n",
      "        [-0.1318],\n",
      "        [-0.1319],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1320],\n",
      "        [-0.1319],\n",
      "        [-0.1318],\n",
      "        [-0.1318],\n",
      "        [-0.1317],\n",
      "        [-0.1317],\n",
      "        [-0.1316],\n",
      "        [-0.1317],\n",
      "        [-0.1317],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1315],\n",
      "        [-0.1315],\n",
      "        [-0.1314],\n",
      "        [-0.1314]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1313],\n",
      "        [-0.1313],\n",
      "        [-0.1313],\n",
      "        [-0.1315],\n",
      "        [-0.1303],\n",
      "        [-0.1312],\n",
      "        [-0.1319],\n",
      "        [-0.1323],\n",
      "        [-0.1325],\n",
      "        [-0.1327],\n",
      "        [-0.1329],\n",
      "        [-0.1330],\n",
      "        [-0.1329],\n",
      "        [-0.1327],\n",
      "        [-0.1324],\n",
      "        [-0.1323],\n",
      "        [-0.1322],\n",
      "        [-0.1320],\n",
      "        [-0.1319],\n",
      "        [-0.1318],\n",
      "        [-0.1318],\n",
      "        [-0.1318],\n",
      "        [-0.1317],\n",
      "        [-0.1317],\n",
      "        [-0.1317],\n",
      "        [-0.1316],\n",
      "        [-0.1316],\n",
      "        [-0.1315],\n",
      "        [-0.1315],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1313],\n",
      "        [-0.1313],\n",
      "        [-0.1314],\n",
      "        [-0.1314],\n",
      "        [-0.1313],\n",
      "        [-0.1312],\n",
      "        [-0.1312],\n",
      "        [-0.1312],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.1309],\n",
      "        [-0.1310],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1307],\n",
      "        [-0.1307],\n",
      "        [-0.1307],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1307],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1307],\n",
      "        [-0.1305],\n",
      "        [-0.1304],\n",
      "        [-0.1308],\n",
      "        [-0.1311],\n",
      "        [-0.1312],\n",
      "        [-0.1313],\n",
      "        [-0.1313],\n",
      "        [-0.1313],\n",
      "        [-0.1312],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1310],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1307],\n",
      "        [-0.1306],\n",
      "        [-0.1306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1305],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1308],\n",
      "        [-0.1296],\n",
      "        [-0.1305],\n",
      "        [-0.1312],\n",
      "        [-0.1316],\n",
      "        [-0.1318],\n",
      "        [-0.1319],\n",
      "        [-0.1321],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.1319],\n",
      "        [-0.1317],\n",
      "        [-0.1315],\n",
      "        [-0.1314],\n",
      "        [-0.1312],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1311],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.1309],\n",
      "        [-0.1309],\n",
      "        [-0.1308],\n",
      "        [-0.1308],\n",
      "        [-0.1307],\n",
      "        [-0.1307],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1306],\n",
      "        [-0.1305],\n",
      "        [-0.1305],\n",
      "        [-0.1305],\n",
      "        [-0.1304],\n",
      "        [-0.1304],\n",
      "        [-0.1304],\n",
      "        [-0.1304],\n",
      "        [-0.1303],\n",
      "        [-0.1303],\n",
      "        [-0.1303],\n",
      "        [-0.1302],\n",
      "        [-0.1302],\n",
      "        [-0.1301],\n",
      "        [-0.1302],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1301],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1298],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1298],\n",
      "        [-0.1297],\n",
      "        [-0.1300],\n",
      "        [-0.1303],\n",
      "        [-0.1304],\n",
      "        [-0.1305],\n",
      "        [-0.1305],\n",
      "        [-0.1305],\n",
      "        [-0.1305],\n",
      "        [-0.1304],\n",
      "        [-0.1303],\n",
      "        [-0.1303],\n",
      "        [-0.1302],\n",
      "        [-0.1302],\n",
      "        [-0.1301],\n",
      "        [-0.1302],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1300],\n",
      "        [-0.1301],\n",
      "        [-0.1300],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1299]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1300],\n",
      "        [-0.1288],\n",
      "        [-0.1297],\n",
      "        [-0.1304],\n",
      "        [-0.1308],\n",
      "        [-0.1310],\n",
      "        [-0.1312],\n",
      "        [-0.1314],\n",
      "        [-0.1315],\n",
      "        [-0.1314],\n",
      "        [-0.1312],\n",
      "        [-0.1309],\n",
      "        [-0.1308],\n",
      "        [-0.1307],\n",
      "        [-0.1305],\n",
      "        [-0.1304],\n",
      "        [-0.1304],\n",
      "        [-0.1303],\n",
      "        [-0.1303],\n",
      "        [-0.1303],\n",
      "        [-0.1302],\n",
      "        [-0.1302],\n",
      "        [-0.1301],\n",
      "        [-0.1301],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1299],\n",
      "        [-0.1299],\n",
      "        [-0.1298],\n",
      "        [-0.1297],\n",
      "        [-0.1297],\n",
      "        [-0.1297],\n",
      "        [-0.1297],\n",
      "        [-0.1296],\n",
      "        [-0.1296],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1294],\n",
      "        [-0.1295],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1292],\n",
      "        [-0.1292],\n",
      "        [-0.1292],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1292],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1292],\n",
      "        [-0.1290],\n",
      "        [-0.1289],\n",
      "        [-0.1293],\n",
      "        [-0.1296],\n",
      "        [-0.1297],\n",
      "        [-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1298],\n",
      "        [-0.1297],\n",
      "        [-0.1296],\n",
      "        [-0.1296],\n",
      "        [-0.1295],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1294],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1292],\n",
      "        [-0.1291],\n",
      "        [-0.1291]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1290],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1292],\n",
      "        [-0.1280],\n",
      "        [-0.1289],\n",
      "        [-0.1297],\n",
      "        [-0.1301],\n",
      "        [-0.1303],\n",
      "        [-0.1304],\n",
      "        [-0.1306],\n",
      "        [-0.1307],\n",
      "        [-0.1307],\n",
      "        [-0.1304],\n",
      "        [-0.1302],\n",
      "        [-0.1300],\n",
      "        [-0.1299],\n",
      "        [-0.1297],\n",
      "        [-0.1296],\n",
      "        [-0.1296],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1295],\n",
      "        [-0.1294],\n",
      "        [-0.1293],\n",
      "        [-0.1293],\n",
      "        [-0.1292],\n",
      "        [-0.1292],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1291],\n",
      "        [-0.1290],\n",
      "        [-0.1290],\n",
      "        [-0.1289],\n",
      "        [-0.1289],\n",
      "        [-0.1289],\n",
      "        [-0.1289],\n",
      "        [-0.1289],\n",
      "        [-0.1288],\n",
      "        [-0.1288],\n",
      "        [-0.1288],\n",
      "        [-0.1287],\n",
      "        [-0.1287],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1285],\n",
      "        [-0.1286],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1284],\n",
      "        [-0.1283],\n",
      "        [-0.1281],\n",
      "        [-0.1285],\n",
      "        [-0.1288],\n",
      "        [-0.1289],\n",
      "        [-0.1290],\n",
      "        [-0.1290],\n",
      "        [-0.1290],\n",
      "        [-0.1290],\n",
      "        [-0.1289],\n",
      "        [-0.1288],\n",
      "        [-0.1287],\n",
      "        [-0.1287],\n",
      "        [-0.1287],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1283]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1285],\n",
      "        [-0.1273],\n",
      "        [-0.1282],\n",
      "        [-0.1289],\n",
      "        [-0.1294],\n",
      "        [-0.1295],\n",
      "        [-0.1297],\n",
      "        [-0.1299],\n",
      "        [-0.1300],\n",
      "        [-0.1300],\n",
      "        [-0.1297],\n",
      "        [-0.1294],\n",
      "        [-0.1293],\n",
      "        [-0.1292],\n",
      "        [-0.1290],\n",
      "        [-0.1289],\n",
      "        [-0.1289],\n",
      "        [-0.1288],\n",
      "        [-0.1288],\n",
      "        [-0.1288],\n",
      "        [-0.1288],\n",
      "        [-0.1287],\n",
      "        [-0.1287],\n",
      "        [-0.1286],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1283],\n",
      "        [-0.1282],\n",
      "        [-0.1282],\n",
      "        [-0.1282],\n",
      "        [-0.1282],\n",
      "        [-0.1282],\n",
      "        [-0.1281],\n",
      "        [-0.1281],\n",
      "        [-0.1281],\n",
      "        [-0.1281],\n",
      "        [-0.1279],\n",
      "        [-0.1280],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1277],\n",
      "        [-0.1275],\n",
      "        [-0.1274],\n",
      "        [-0.1278],\n",
      "        [-0.1281],\n",
      "        [-0.1282],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1283],\n",
      "        [-0.1282],\n",
      "        [-0.1281],\n",
      "        [-0.1280],\n",
      "        [-0.1280],\n",
      "        [-0.1280],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1277],\n",
      "        [-0.1276],\n",
      "        [-0.1276]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1275],\n",
      "        [-0.1275],\n",
      "        [-0.1275],\n",
      "        [-0.1277],\n",
      "        [-0.1265],\n",
      "        [-0.1274],\n",
      "        [-0.1281],\n",
      "        [-0.1286],\n",
      "        [-0.1287],\n",
      "        [-0.1289],\n",
      "        [-0.1291],\n",
      "        [-0.1292],\n",
      "        [-0.1292],\n",
      "        [-0.1289],\n",
      "        [-0.1286],\n",
      "        [-0.1285],\n",
      "        [-0.1284],\n",
      "        [-0.1282],\n",
      "        [-0.1281],\n",
      "        [-0.1281],\n",
      "        [-0.1280],\n",
      "        [-0.1280],\n",
      "        [-0.1280],\n",
      "        [-0.1279],\n",
      "        [-0.1279],\n",
      "        [-0.1278],\n",
      "        [-0.1278],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1275],\n",
      "        [-0.1275],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.1275],\n",
      "        [-0.1274],\n",
      "        [-0.1274],\n",
      "        [-0.1274],\n",
      "        [-0.1274],\n",
      "        [-0.1273],\n",
      "        [-0.1273],\n",
      "        [-0.1273],\n",
      "        [-0.1272],\n",
      "        [-0.1272],\n",
      "        [-0.1271],\n",
      "        [-0.1272],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1269],\n",
      "        [-0.1269],\n",
      "        [-0.1269],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1269],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1269],\n",
      "        [-0.1267],\n",
      "        [-0.1266],\n",
      "        [-0.1270],\n",
      "        [-0.1273],\n",
      "        [-0.1274],\n",
      "        [-0.1275],\n",
      "        [-0.1275],\n",
      "        [-0.1275],\n",
      "        [-0.1274],\n",
      "        [-0.1273],\n",
      "        [-0.1273],\n",
      "        [-0.1272],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1269],\n",
      "        [-0.1268],\n",
      "        [-0.1268]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1270],\n",
      "        [-0.1258],\n",
      "        [-0.1267],\n",
      "        [-0.1274],\n",
      "        [-0.1278],\n",
      "        [-0.1280],\n",
      "        [-0.1282],\n",
      "        [-0.1284],\n",
      "        [-0.1285],\n",
      "        [-0.1284],\n",
      "        [-0.1282],\n",
      "        [-0.1279],\n",
      "        [-0.1278],\n",
      "        [-0.1277],\n",
      "        [-0.1275],\n",
      "        [-0.1274],\n",
      "        [-0.1274],\n",
      "        [-0.1273],\n",
      "        [-0.1273],\n",
      "        [-0.1273],\n",
      "        [-0.1272],\n",
      "        [-0.1272],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.1270],\n",
      "        [-0.1270],\n",
      "        [-0.1269],\n",
      "        [-0.1269],\n",
      "        [-0.1269],\n",
      "        [-0.1269],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1269],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1267],\n",
      "        [-0.1267],\n",
      "        [-0.1267],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.1265],\n",
      "        [-0.1265],\n",
      "        [-0.1265],\n",
      "        [-0.1264],\n",
      "        [-0.1265],\n",
      "        [-0.1264],\n",
      "        [-0.1264],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1262],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1262],\n",
      "        [-0.1262],\n",
      "        [-0.1262],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1260],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1262],\n",
      "        [-0.1260],\n",
      "        [-0.1259],\n",
      "        [-0.1263],\n",
      "        [-0.1266],\n",
      "        [-0.1267],\n",
      "        [-0.1267],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [-0.1267],\n",
      "        [-0.1266],\n",
      "        [-0.1265],\n",
      "        [-0.1265],\n",
      "        [-0.1264],\n",
      "        [-0.1264],\n",
      "        [-0.1263],\n",
      "        [-0.1264],\n",
      "        [-0.1264],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1262],\n",
      "        [-0.1262],\n",
      "        [-0.1261],\n",
      "        [-0.1261]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1260],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1262],\n",
      "        [-0.1250],\n",
      "        [-0.1259],\n",
      "        [-0.1267],\n",
      "        [-0.1271],\n",
      "        [-0.1273],\n",
      "        [-0.1274],\n",
      "        [-0.1276],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.1274],\n",
      "        [-0.1272],\n",
      "        [-0.1271],\n",
      "        [-0.1270],\n",
      "        [-0.1268],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.1265],\n",
      "        [-0.1265],\n",
      "        [-0.1265],\n",
      "        [-0.1264],\n",
      "        [-0.1264],\n",
      "        [-0.1263],\n",
      "        [-0.1263],\n",
      "        [-0.1262],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1261],\n",
      "        [-0.1260],\n",
      "        [-0.1260],\n",
      "        [-0.1259],\n",
      "        [-0.1259],\n",
      "        [-0.1259],\n",
      "        [-0.1259],\n",
      "        [-0.1259],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1257],\n",
      "        [-0.1257],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1255],\n",
      "        [-0.1256],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1254],\n",
      "        [-0.1253],\n",
      "        [-0.1251],\n",
      "        [-0.1255],\n",
      "        [-0.1258],\n",
      "        [-0.1259],\n",
      "        [-0.1260],\n",
      "        [-0.1260],\n",
      "        [-0.1260],\n",
      "        [-0.1260],\n",
      "        [-0.1259],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1257],\n",
      "        [-0.1257],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch  80 Train Loss:  0.6480\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1252],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1255],\n",
      "        [-0.1242],\n",
      "        [-0.1251],\n",
      "        [-0.1259],\n",
      "        [-0.1263],\n",
      "        [-0.1265],\n",
      "        [-0.1267],\n",
      "        [-0.1269],\n",
      "        [-0.1270],\n",
      "        [-0.1269],\n",
      "        [-0.1266],\n",
      "        [-0.1264],\n",
      "        [-0.1263],\n",
      "        [-0.1262],\n",
      "        [-0.1260],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1258],\n",
      "        [-0.1257],\n",
      "        [-0.1257],\n",
      "        [-0.1257],\n",
      "        [-0.1256],\n",
      "        [-0.1256],\n",
      "        [-0.1255],\n",
      "        [-0.1255],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1253],\n",
      "        [-0.1252],\n",
      "        [-0.1252],\n",
      "        [-0.1252],\n",
      "        [-0.1251],\n",
      "        [-0.1251],\n",
      "        [-0.1251],\n",
      "        [-0.1251],\n",
      "        [-0.1250],\n",
      "        [-0.1250],\n",
      "        [-0.1250],\n",
      "        [-0.1249],\n",
      "        [-0.1249],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1247],\n",
      "        [-0.1248],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1246],\n",
      "        [-0.1245],\n",
      "        [-0.1243],\n",
      "        [-0.1247],\n",
      "        [-0.1250],\n",
      "        [-0.1251],\n",
      "        [-0.1252],\n",
      "        [-0.1252],\n",
      "        [-0.1252],\n",
      "        [-0.1252],\n",
      "        [-0.1251],\n",
      "        [-0.1250],\n",
      "        [-0.1250],\n",
      "        [-0.1249],\n",
      "        [-0.1249],\n",
      "        [-0.1248],\n",
      "        [-0.1249],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1246],\n",
      "        [-0.1247],\n",
      "        [-0.1235],\n",
      "        [-0.1244],\n",
      "        [-0.1252],\n",
      "        [-0.1256],\n",
      "        [-0.1258],\n",
      "        [-0.1259],\n",
      "        [-0.1261],\n",
      "        [-0.1262],\n",
      "        [-0.1262],\n",
      "        [-0.1259],\n",
      "        [-0.1257],\n",
      "        [-0.1255],\n",
      "        [-0.1254],\n",
      "        [-0.1252],\n",
      "        [-0.1251],\n",
      "        [-0.1251],\n",
      "        [-0.1250],\n",
      "        [-0.1251],\n",
      "        [-0.1250],\n",
      "        [-0.1250],\n",
      "        [-0.1250],\n",
      "        [-0.1249],\n",
      "        [-0.1248],\n",
      "        [-0.1248],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1245],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1246],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1244],\n",
      "        [-0.1244],\n",
      "        [-0.1244],\n",
      "        [-0.1244],\n",
      "        [-0.1244],\n",
      "        [-0.1243],\n",
      "        [-0.1243],\n",
      "        [-0.1243],\n",
      "        [-0.1241],\n",
      "        [-0.1242],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1239],\n",
      "        [-0.1239],\n",
      "        [-0.1239],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1239],\n",
      "        [-0.1239],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1239],\n",
      "        [-0.1237],\n",
      "        [-0.1236],\n",
      "        [-0.1240],\n",
      "        [-0.1243],\n",
      "        [-0.1244],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1245],\n",
      "        [-0.1244],\n",
      "        [-0.1243],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1241],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1239],\n",
      "        [-0.1238],\n",
      "        [-0.1238]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1239],\n",
      "        [-0.1226],\n",
      "        [-0.1236],\n",
      "        [-0.1244],\n",
      "        [-0.1248],\n",
      "        [-0.1250],\n",
      "        [-0.1251],\n",
      "        [-0.1253],\n",
      "        [-0.1254],\n",
      "        [-0.1254],\n",
      "        [-0.1251],\n",
      "        [-0.1249],\n",
      "        [-0.1247],\n",
      "        [-0.1246],\n",
      "        [-0.1244],\n",
      "        [-0.1243],\n",
      "        [-0.1243],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1242],\n",
      "        [-0.1241],\n",
      "        [-0.1240],\n",
      "        [-0.1240],\n",
      "        [-0.1239],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1238],\n",
      "        [-0.1238],\n",
      "        [-0.1237],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1235],\n",
      "        [-0.1235],\n",
      "        [-0.1234],\n",
      "        [-0.1234],\n",
      "        [-0.1234],\n",
      "        [-0.1233],\n",
      "        [-0.1234],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1231],\n",
      "        [-0.1231],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1231],\n",
      "        [-0.1229],\n",
      "        [-0.1228],\n",
      "        [-0.1232],\n",
      "        [-0.1235],\n",
      "        [-0.1236],\n",
      "        [-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1237],\n",
      "        [-0.1236],\n",
      "        [-0.1235],\n",
      "        [-0.1234],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1231],\n",
      "        [-0.1230],\n",
      "        [-0.1230]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1232],\n",
      "        [-0.1219],\n",
      "        [-0.1229],\n",
      "        [-0.1236],\n",
      "        [-0.1241],\n",
      "        [-0.1243],\n",
      "        [-0.1244],\n",
      "        [-0.1246],\n",
      "        [-0.1247],\n",
      "        [-0.1247],\n",
      "        [-0.1244],\n",
      "        [-0.1241],\n",
      "        [-0.1240],\n",
      "        [-0.1239],\n",
      "        [-0.1237],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1235],\n",
      "        [-0.1235],\n",
      "        [-0.1235],\n",
      "        [-0.1234],\n",
      "        [-0.1234],\n",
      "        [-0.1233],\n",
      "        [-0.1233],\n",
      "        [-0.1232],\n",
      "        [-0.1232],\n",
      "        [-0.1231],\n",
      "        [-0.1231],\n",
      "        [-0.1231],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1231],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1229],\n",
      "        [-0.1229],\n",
      "        [-0.1229],\n",
      "        [-0.1228],\n",
      "        [-0.1228],\n",
      "        [-0.1228],\n",
      "        [-0.1227],\n",
      "        [-0.1227],\n",
      "        [-0.1227],\n",
      "        [-0.1226],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1225],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1222],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1222],\n",
      "        [-0.1220],\n",
      "        [-0.1225],\n",
      "        [-0.1228],\n",
      "        [-0.1229],\n",
      "        [-0.1229],\n",
      "        [-0.1230],\n",
      "        [-0.1230],\n",
      "        [-0.1229],\n",
      "        [-0.1228],\n",
      "        [-0.1227],\n",
      "        [-0.1227],\n",
      "        [-0.1226],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1226],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1224],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1224],\n",
      "        [-0.1211],\n",
      "        [-0.1221],\n",
      "        [-0.1229],\n",
      "        [-0.1233],\n",
      "        [-0.1235],\n",
      "        [-0.1236],\n",
      "        [-0.1238],\n",
      "        [-0.1239],\n",
      "        [-0.1239],\n",
      "        [-0.1236],\n",
      "        [-0.1234],\n",
      "        [-0.1233],\n",
      "        [-0.1231],\n",
      "        [-0.1229],\n",
      "        [-0.1228],\n",
      "        [-0.1228],\n",
      "        [-0.1227],\n",
      "        [-0.1228],\n",
      "        [-0.1227],\n",
      "        [-0.1227],\n",
      "        [-0.1227],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1225],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1222],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1223],\n",
      "        [-0.1222],\n",
      "        [-0.1221],\n",
      "        [-0.1221],\n",
      "        [-0.1221],\n",
      "        [-0.1221],\n",
      "        [-0.1221],\n",
      "        [-0.1220],\n",
      "        [-0.1220],\n",
      "        [-0.1220],\n",
      "        [-0.1220],\n",
      "        [-0.1218],\n",
      "        [-0.1219],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1216],\n",
      "        [-0.1216],\n",
      "        [-0.1216],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1216],\n",
      "        [-0.1214],\n",
      "        [-0.1213],\n",
      "        [-0.1217],\n",
      "        [-0.1220],\n",
      "        [-0.1221],\n",
      "        [-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1222],\n",
      "        [-0.1221],\n",
      "        [-0.1220],\n",
      "        [-0.1219],\n",
      "        [-0.1219],\n",
      "        [-0.1219],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1216],\n",
      "        [-0.1215],\n",
      "        [-0.1215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1214],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1217],\n",
      "        [-0.1204],\n",
      "        [-0.1213],\n",
      "        [-0.1221],\n",
      "        [-0.1225],\n",
      "        [-0.1227],\n",
      "        [-0.1229],\n",
      "        [-0.1231],\n",
      "        [-0.1232],\n",
      "        [-0.1231],\n",
      "        [-0.1229],\n",
      "        [-0.1226],\n",
      "        [-0.1225],\n",
      "        [-0.1224],\n",
      "        [-0.1222],\n",
      "        [-0.1221],\n",
      "        [-0.1220],\n",
      "        [-0.1220],\n",
      "        [-0.1220],\n",
      "        [-0.1219],\n",
      "        [-0.1219],\n",
      "        [-0.1219],\n",
      "        [-0.1218],\n",
      "        [-0.1218],\n",
      "        [-0.1217],\n",
      "        [-0.1217],\n",
      "        [-0.1216],\n",
      "        [-0.1216],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1215],\n",
      "        [-0.1214],\n",
      "        [-0.1214],\n",
      "        [-0.1214],\n",
      "        [-0.1213],\n",
      "        [-0.1213],\n",
      "        [-0.1213],\n",
      "        [-0.1213],\n",
      "        [-0.1212],\n",
      "        [-0.1212],\n",
      "        [-0.1212],\n",
      "        [-0.1211],\n",
      "        [-0.1211],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1209],\n",
      "        [-0.1210],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1208],\n",
      "        [-0.1206],\n",
      "        [-0.1205],\n",
      "        [-0.1209],\n",
      "        [-0.1212],\n",
      "        [-0.1213],\n",
      "        [-0.1214],\n",
      "        [-0.1214],\n",
      "        [-0.1214],\n",
      "        [-0.1214],\n",
      "        [-0.1213],\n",
      "        [-0.1212],\n",
      "        [-0.1212],\n",
      "        [-0.1211],\n",
      "        [-0.1211],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1209],\n",
      "        [-0.1196],\n",
      "        [-0.1206],\n",
      "        [-0.1214],\n",
      "        [-0.1218],\n",
      "        [-0.1220],\n",
      "        [-0.1222],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1224],\n",
      "        [-0.1221],\n",
      "        [-0.1219],\n",
      "        [-0.1218],\n",
      "        [-0.1216],\n",
      "        [-0.1214],\n",
      "        [-0.1213],\n",
      "        [-0.1213],\n",
      "        [-0.1212],\n",
      "        [-0.1213],\n",
      "        [-0.1212],\n",
      "        [-0.1212],\n",
      "        [-0.1212],\n",
      "        [-0.1211],\n",
      "        [-0.1210],\n",
      "        [-0.1210],\n",
      "        [-0.1209],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1208],\n",
      "        [-0.1208],\n",
      "        [-0.1207],\n",
      "        [-0.1206],\n",
      "        [-0.1206],\n",
      "        [-0.1206],\n",
      "        [-0.1206],\n",
      "        [-0.1205],\n",
      "        [-0.1205],\n",
      "        [-0.1204],\n",
      "        [-0.1204],\n",
      "        [-0.1204],\n",
      "        [-0.1203],\n",
      "        [-0.1204],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1201],\n",
      "        [-0.1201],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1199],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1201],\n",
      "        [-0.1199],\n",
      "        [-0.1198],\n",
      "        [-0.1202],\n",
      "        [-0.1205],\n",
      "        [-0.1206],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1207],\n",
      "        [-0.1206],\n",
      "        [-0.1205],\n",
      "        [-0.1204],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1203],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1201],\n",
      "        [-0.1200],\n",
      "        [-0.1200]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1201],\n",
      "        [-0.1188],\n",
      "        [-0.1198],\n",
      "        [-0.1206],\n",
      "        [-0.1210],\n",
      "        [-0.1212],\n",
      "        [-0.1214],\n",
      "        [-0.1216],\n",
      "        [-0.1216],\n",
      "        [-0.1216],\n",
      "        [-0.1213],\n",
      "        [-0.1211],\n",
      "        [-0.1210],\n",
      "        [-0.1208],\n",
      "        [-0.1206],\n",
      "        [-0.1205],\n",
      "        [-0.1205],\n",
      "        [-0.1204],\n",
      "        [-0.1205],\n",
      "        [-0.1204],\n",
      "        [-0.1204],\n",
      "        [-0.1204],\n",
      "        [-0.1203],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1201],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1200],\n",
      "        [-0.1200],\n",
      "        [-0.1199],\n",
      "        [-0.1198],\n",
      "        [-0.1198],\n",
      "        [-0.1198],\n",
      "        [-0.1198],\n",
      "        [-0.1197],\n",
      "        [-0.1197],\n",
      "        [-0.1196],\n",
      "        [-0.1196],\n",
      "        [-0.1196],\n",
      "        [-0.1195],\n",
      "        [-0.1196],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1193],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1193],\n",
      "        [-0.1193],\n",
      "        [-0.1193],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1191],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1193],\n",
      "        [-0.1191],\n",
      "        [-0.1190],\n",
      "        [-0.1194],\n",
      "        [-0.1197],\n",
      "        [-0.1198],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1198],\n",
      "        [-0.1197],\n",
      "        [-0.1196],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1193],\n",
      "        [-0.1193],\n",
      "        [-0.1192],\n",
      "        [-0.1192]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1191],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1194],\n",
      "        [-0.1180],\n",
      "        [-0.1190],\n",
      "        [-0.1198],\n",
      "        [-0.1203],\n",
      "        [-0.1205],\n",
      "        [-0.1206],\n",
      "        [-0.1208],\n",
      "        [-0.1209],\n",
      "        [-0.1209],\n",
      "        [-0.1206],\n",
      "        [-0.1203],\n",
      "        [-0.1202],\n",
      "        [-0.1201],\n",
      "        [-0.1199],\n",
      "        [-0.1198],\n",
      "        [-0.1197],\n",
      "        [-0.1197],\n",
      "        [-0.1197],\n",
      "        [-0.1197],\n",
      "        [-0.1196],\n",
      "        [-0.1196],\n",
      "        [-0.1195],\n",
      "        [-0.1195],\n",
      "        [-0.1194],\n",
      "        [-0.1194],\n",
      "        [-0.1193],\n",
      "        [-0.1193],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1192],\n",
      "        [-0.1191],\n",
      "        [-0.1191],\n",
      "        [-0.1191],\n",
      "        [-0.1190],\n",
      "        [-0.1190],\n",
      "        [-0.1190],\n",
      "        [-0.1190],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1188],\n",
      "        [-0.1188],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1186],\n",
      "        [-0.1187],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1185],\n",
      "        [-0.1185],\n",
      "        [-0.1185],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1185],\n",
      "        [-0.1185],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1185],\n",
      "        [-0.1183],\n",
      "        [-0.1182],\n",
      "        [-0.1186],\n",
      "        [-0.1190],\n",
      "        [-0.1190],\n",
      "        [-0.1191],\n",
      "        [-0.1191],\n",
      "        [-0.1191],\n",
      "        [-0.1191],\n",
      "        [-0.1190],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1188],\n",
      "        [-0.1188],\n",
      "        [-0.1187],\n",
      "        [-0.1188],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1185],\n",
      "        [-0.1185],\n",
      "        [-0.1184]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1183],\n",
      "        [-0.1183],\n",
      "        [-0.1184],\n",
      "        [-0.1185],\n",
      "        [-0.1172],\n",
      "        [-0.1182],\n",
      "        [-0.1190],\n",
      "        [-0.1195],\n",
      "        [-0.1197],\n",
      "        [-0.1198],\n",
      "        [-0.1200],\n",
      "        [-0.1201],\n",
      "        [-0.1200],\n",
      "        [-0.1198],\n",
      "        [-0.1195],\n",
      "        [-0.1194],\n",
      "        [-0.1193],\n",
      "        [-0.1191],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.1188],\n",
      "        [-0.1188],\n",
      "        [-0.1188],\n",
      "        [-0.1187],\n",
      "        [-0.1187],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1185],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1184],\n",
      "        [-0.1183],\n",
      "        [-0.1183],\n",
      "        [-0.1182],\n",
      "        [-0.1182],\n",
      "        [-0.1182],\n",
      "        [-0.1182],\n",
      "        [-0.1182],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1179],\n",
      "        [-0.1180],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1177],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1177],\n",
      "        [-0.1175],\n",
      "        [-0.1174],\n",
      "        [-0.1178],\n",
      "        [-0.1181],\n",
      "        [-0.1182],\n",
      "        [-0.1183],\n",
      "        [-0.1183],\n",
      "        [-0.1183],\n",
      "        [-0.1183],\n",
      "        [-0.1182],\n",
      "        [-0.1181],\n",
      "        [-0.1180],\n",
      "        [-0.1180],\n",
      "        [-0.1180],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1179],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1177],\n",
      "        [-0.1176],\n",
      "        [-0.1176]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1175],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1178],\n",
      "        [-0.1164],\n",
      "        [-0.1175],\n",
      "        [-0.1183],\n",
      "        [-0.1187],\n",
      "        [-0.1189],\n",
      "        [-0.1190],\n",
      "        [-0.1192],\n",
      "        [-0.1193],\n",
      "        [-0.1193],\n",
      "        [-0.1190],\n",
      "        [-0.1188],\n",
      "        [-0.1186],\n",
      "        [-0.1185],\n",
      "        [-0.1183],\n",
      "        [-0.1182],\n",
      "        [-0.1182],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1181],\n",
      "        [-0.1180],\n",
      "        [-0.1179],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1177],\n",
      "        [-0.1177],\n",
      "        [-0.1176],\n",
      "        [-0.1175],\n",
      "        [-0.1175],\n",
      "        [-0.1175],\n",
      "        [-0.1174],\n",
      "        [-0.1174],\n",
      "        [-0.1174],\n",
      "        [-0.1173],\n",
      "        [-0.1173],\n",
      "        [-0.1173],\n",
      "        [-0.1172],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1170],\n",
      "        [-0.1170],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1170],\n",
      "        [-0.1170],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1169],\n",
      "        [-0.1168],\n",
      "        [-0.1166],\n",
      "        [-0.1171],\n",
      "        [-0.1174],\n",
      "        [-0.1175],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1176],\n",
      "        [-0.1175],\n",
      "        [-0.1174],\n",
      "        [-0.1173],\n",
      "        [-0.1173],\n",
      "        [-0.1172],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1169],\n",
      "        [-0.1171],\n",
      "        [-0.1157],\n",
      "        [-0.1167],\n",
      "        [-0.1175],\n",
      "        [-0.1180],\n",
      "        [-0.1182],\n",
      "        [-0.1183],\n",
      "        [-0.1185],\n",
      "        [-0.1186],\n",
      "        [-0.1186],\n",
      "        [-0.1183],\n",
      "        [-0.1180],\n",
      "        [-0.1179],\n",
      "        [-0.1178],\n",
      "        [-0.1176],\n",
      "        [-0.1175],\n",
      "        [-0.1175],\n",
      "        [-0.1174],\n",
      "        [-0.1174],\n",
      "        [-0.1174],\n",
      "        [-0.1173],\n",
      "        [-0.1173],\n",
      "        [-0.1172],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1170],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1169],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1167],\n",
      "        [-0.1167],\n",
      "        [-0.1167],\n",
      "        [-0.1167],\n",
      "        [-0.1166],\n",
      "        [-0.1166],\n",
      "        [-0.1166],\n",
      "        [-0.1164],\n",
      "        [-0.1165],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1162],\n",
      "        [-0.1162],\n",
      "        [-0.1162],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1162],\n",
      "        [-0.1162],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1162],\n",
      "        [-0.1160],\n",
      "        [-0.1159],\n",
      "        [-0.1163],\n",
      "        [-0.1167],\n",
      "        [-0.1167],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1168],\n",
      "        [-0.1167],\n",
      "        [-0.1166],\n",
      "        [-0.1165],\n",
      "        [-0.1165],\n",
      "        [-0.1165],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1162],\n",
      "        [-0.1161],\n",
      "        [-0.1161]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1160],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1163],\n",
      "        [-0.1149],\n",
      "        [-0.1159],\n",
      "        [-0.1168],\n",
      "        [-0.1172],\n",
      "        [-0.1174],\n",
      "        [-0.1175],\n",
      "        [-0.1177],\n",
      "        [-0.1178],\n",
      "        [-0.1178],\n",
      "        [-0.1175],\n",
      "        [-0.1172],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1168],\n",
      "        [-0.1167],\n",
      "        [-0.1167],\n",
      "        [-0.1166],\n",
      "        [-0.1166],\n",
      "        [-0.1166],\n",
      "        [-0.1165],\n",
      "        [-0.1165],\n",
      "        [-0.1164],\n",
      "        [-0.1164],\n",
      "        [-0.1163],\n",
      "        [-0.1163],\n",
      "        [-0.1162],\n",
      "        [-0.1162],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1161],\n",
      "        [-0.1160],\n",
      "        [-0.1160],\n",
      "        [-0.1160],\n",
      "        [-0.1159],\n",
      "        [-0.1159],\n",
      "        [-0.1159],\n",
      "        [-0.1159],\n",
      "        [-0.1158],\n",
      "        [-0.1158],\n",
      "        [-0.1158],\n",
      "        [-0.1156],\n",
      "        [-0.1157],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1154],\n",
      "        [-0.1152],\n",
      "        [-0.1151],\n",
      "        [-0.1155],\n",
      "        [-0.1159],\n",
      "        [-0.1160],\n",
      "        [-0.1160],\n",
      "        [-0.1160],\n",
      "        [-0.1161],\n",
      "        [-0.1160],\n",
      "        [-0.1159],\n",
      "        [-0.1158],\n",
      "        [-0.1158],\n",
      "        [-0.1157],\n",
      "        [-0.1157],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1153]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1155],\n",
      "        [-0.1141],\n",
      "        [-0.1152],\n",
      "        [-0.1160],\n",
      "        [-0.1164],\n",
      "        [-0.1166],\n",
      "        [-0.1168],\n",
      "        [-0.1170],\n",
      "        [-0.1171],\n",
      "        [-0.1170],\n",
      "        [-0.1168],\n",
      "        [-0.1165],\n",
      "        [-0.1164],\n",
      "        [-0.1162],\n",
      "        [-0.1160],\n",
      "        [-0.1159],\n",
      "        [-0.1159],\n",
      "        [-0.1158],\n",
      "        [-0.1159],\n",
      "        [-0.1158],\n",
      "        [-0.1158],\n",
      "        [-0.1158],\n",
      "        [-0.1157],\n",
      "        [-0.1156],\n",
      "        [-0.1156],\n",
      "        [-0.1155],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1154],\n",
      "        [-0.1154],\n",
      "        [-0.1153],\n",
      "        [-0.1152],\n",
      "        [-0.1152],\n",
      "        [-0.1152],\n",
      "        [-0.1151],\n",
      "        [-0.1151],\n",
      "        [-0.1151],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1149],\n",
      "        [-0.1150],\n",
      "        [-0.1148],\n",
      "        [-0.1149],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1147],\n",
      "        [-0.1147],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1147],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1143],\n",
      "        [-0.1148],\n",
      "        [-0.1151],\n",
      "        [-0.1152],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1153],\n",
      "        [-0.1152],\n",
      "        [-0.1151],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1149],\n",
      "        [-0.1149],\n",
      "        [-0.1148],\n",
      "        [-0.1149],\n",
      "        [-0.1149],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1146]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1144],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1147],\n",
      "        [-0.1133],\n",
      "        [-0.1144],\n",
      "        [-0.1152],\n",
      "        [-0.1156],\n",
      "        [-0.1158],\n",
      "        [-0.1160],\n",
      "        [-0.1162],\n",
      "        [-0.1163],\n",
      "        [-0.1162],\n",
      "        [-0.1159],\n",
      "        [-0.1157],\n",
      "        [-0.1156],\n",
      "        [-0.1154],\n",
      "        [-0.1152],\n",
      "        [-0.1151],\n",
      "        [-0.1151],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1150],\n",
      "        [-0.1149],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1146],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1142],\n",
      "        [-0.1142],\n",
      "        [-0.1141],\n",
      "        [-0.1141],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1139],\n",
      "        [-0.1140],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1138],\n",
      "        [-0.1136],\n",
      "        [-0.1135],\n",
      "        [-0.1139],\n",
      "        [-0.1143],\n",
      "        [-0.1144],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1142],\n",
      "        [-0.1141],\n",
      "        [-0.1141],\n",
      "        [-0.1140],\n",
      "        [-0.1141],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1137]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1138],\n",
      "        [-0.1139],\n",
      "        [-0.1125],\n",
      "        [-0.1136],\n",
      "        [-0.1144],\n",
      "        [-0.1149],\n",
      "        [-0.1151],\n",
      "        [-0.1152],\n",
      "        [-0.1154],\n",
      "        [-0.1155],\n",
      "        [-0.1155],\n",
      "        [-0.1152],\n",
      "        [-0.1149],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1142],\n",
      "        [-0.1141],\n",
      "        [-0.1141],\n",
      "        [-0.1140],\n",
      "        [-0.1140],\n",
      "        [-0.1139],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1138],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1133],\n",
      "        [-0.1134],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1131],\n",
      "        [-0.1131],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1129],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1131],\n",
      "        [-0.1129],\n",
      "        [-0.1128],\n",
      "        [-0.1132],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1137],\n",
      "        [-0.1136],\n",
      "        [-0.1135],\n",
      "        [-0.1134],\n",
      "        [-0.1134],\n",
      "        [-0.1134],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1133],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1131],\n",
      "        [-0.1130],\n",
      "        [-0.1130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1129],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1132],\n",
      "        [-0.1118],\n",
      "        [-0.1128],\n",
      "        [-0.1137],\n",
      "        [-0.1141],\n",
      "        [-0.1143],\n",
      "        [-0.1145],\n",
      "        [-0.1147],\n",
      "        [-0.1148],\n",
      "        [-0.1147],\n",
      "        [-0.1144],\n",
      "        [-0.1142],\n",
      "        [-0.1140],\n",
      "        [-0.1139],\n",
      "        [-0.1137],\n",
      "        [-0.1136],\n",
      "        [-0.1136],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1135],\n",
      "        [-0.1134],\n",
      "        [-0.1133],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1131],\n",
      "        [-0.1131],\n",
      "        [-0.1131],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1131],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1129],\n",
      "        [-0.1129],\n",
      "        [-0.1129],\n",
      "        [-0.1128],\n",
      "        [-0.1128],\n",
      "        [-0.1128],\n",
      "        [-0.1127],\n",
      "        [-0.1127],\n",
      "        [-0.1127],\n",
      "        [-0.1126],\n",
      "        [-0.1126],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1124],\n",
      "        [-0.1125],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1123],\n",
      "        [-0.1123],\n",
      "        [-0.1123],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1123],\n",
      "        [-0.1123],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1123],\n",
      "        [-0.1121],\n",
      "        [-0.1120],\n",
      "        [-0.1124],\n",
      "        [-0.1128],\n",
      "        [-0.1129],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1130],\n",
      "        [-0.1129],\n",
      "        [-0.1128],\n",
      "        [-0.1127],\n",
      "        [-0.1127],\n",
      "        [-0.1126],\n",
      "        [-0.1126],\n",
      "        [-0.1125],\n",
      "        [-0.1126],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1123],\n",
      "        [-0.1123],\n",
      "        [-0.1122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1122],\n",
      "        [-0.1124],\n",
      "        [-0.1109],\n",
      "        [-0.1120],\n",
      "        [-0.1129],\n",
      "        [-0.1133],\n",
      "        [-0.1135],\n",
      "        [-0.1136],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1139],\n",
      "        [-0.1136],\n",
      "        [-0.1134],\n",
      "        [-0.1132],\n",
      "        [-0.1131],\n",
      "        [-0.1129],\n",
      "        [-0.1128],\n",
      "        [-0.1128],\n",
      "        [-0.1127],\n",
      "        [-0.1127],\n",
      "        [-0.1127],\n",
      "        [-0.1126],\n",
      "        [-0.1126],\n",
      "        [-0.1125],\n",
      "        [-0.1125],\n",
      "        [-0.1124],\n",
      "        [-0.1124],\n",
      "        [-0.1123],\n",
      "        [-0.1123],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1122],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1119],\n",
      "        [-0.1119],\n",
      "        [-0.1119],\n",
      "        [-0.1117],\n",
      "        [-0.1118],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1115],\n",
      "        [-0.1115],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1113],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1115],\n",
      "        [-0.1113],\n",
      "        [-0.1112],\n",
      "        [-0.1116],\n",
      "        [-0.1120],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1121],\n",
      "        [-0.1120],\n",
      "        [-0.1119],\n",
      "        [-0.1118],\n",
      "        [-0.1118],\n",
      "        [-0.1118],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1117],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1115],\n",
      "        [-0.1114],\n",
      "        [-0.1114]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([100, 20, 2])\n",
      "----------------\n",
      "tensor([[-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1116],\n",
      "        [-0.1102],\n",
      "        [-0.1113],\n",
      "        [-0.1121],\n",
      "        [-0.1126],\n",
      "        [-0.1128],\n",
      "        [-0.1129],\n",
      "        [-0.1131],\n",
      "        [-0.1132],\n",
      "        [-0.1132],\n",
      "        [-0.1129],\n",
      "        [-0.1126],\n",
      "        [-0.1125],\n",
      "        [-0.1124],\n",
      "        [-0.1122],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.1119],\n",
      "        [-0.1119],\n",
      "        [-0.1119],\n",
      "        [-0.1118],\n",
      "        [-0.1118],\n",
      "        [-0.1117],\n",
      "        [-0.1116],\n",
      "        [-0.1116],\n",
      "        [-0.1115],\n",
      "        [-0.1115],\n",
      "        [-0.1115],\n",
      "        [-0.1114],\n",
      "        [-0.1115],\n",
      "        [-0.1115],\n",
      "        [-0.1115],\n",
      "        [-0.1114],\n",
      "        [-0.1113],\n",
      "        [-0.1113],\n",
      "        [-0.1113],\n",
      "        [-0.1113],\n",
      "        [-0.1112],\n",
      "        [-0.1112],\n",
      "        [-0.1111],\n",
      "        [-0.1111],\n",
      "        [-0.1111],\n",
      "        [-0.1110],\n",
      "        [-0.1111],\n",
      "        [-0.1109],\n",
      "        [-0.1110],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1108],\n",
      "        [-0.1108],\n",
      "        [-0.1109],\n",
      "        [-0.1108],\n",
      "        [-0.1108],\n",
      "        [-0.1108],\n",
      "        [-0.1108],\n",
      "        [-0.1107],\n",
      "        [-0.1106],\n",
      "        [-0.1106],\n",
      "        [-0.1106],\n",
      "        [-0.1107],\n",
      "        [-0.1107],\n",
      "        [-0.1107],\n",
      "        [-0.1107],\n",
      "        [-0.1106],\n",
      "        [-0.1106],\n",
      "        [-0.1107],\n",
      "        [-0.1106],\n",
      "        [-0.1104],\n",
      "        [-0.1109],\n",
      "        [-0.1112],\n",
      "        [-0.1113],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1114],\n",
      "        [-0.1113],\n",
      "        [-0.1112],\n",
      "        [-0.1111],\n",
      "        [-0.1110],\n",
      "        [-0.1110],\n",
      "        [-0.1109],\n",
      "        [-0.1110],\n",
      "        [-0.1110],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1109],\n",
      "        [-0.1108],\n",
      "        [-0.1107],\n",
      "        [-0.1107],\n",
      "        [-0.1107]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, train_history = train_model(LSTM, dataloader, epochs=CFG['EPOCHS'], lr=CFG['LEARNING_RATE'], verbose=20, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [63]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43moutputs\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455afc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
